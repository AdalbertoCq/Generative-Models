# Generative-Models
This is a repository to keep track of the papers on different generative models.


## VAEs.
* ["Auto-Encoding Variational Bayes" Welling M, et al. 2013](arxiv.org/abs/1312.6114)
* ["Tutorial on Variational Autoencoders" Doersch C, et al. 2016](https://arxiv.org/abs/1606.05908)

* Conditional VAEs:
  * ["Learning Structured Output Representation using Deep Conditional Generative Models" Sohn K, Yan X, Lee H, et al. 2014](https://papers.nips.cc/paper/5775-learning-structured-output-representation-using-deep-conditional-generative-models)

* Wasserstein Auto-Encoders:
  * ["Wasserstein Auto-Encoders" Tolstikhin I, Bousquet O Gelly S, Schölkopf B, et al. 2018](https://arxiv.org/pdf/1711.01558.pdf)
  
 * VAE + GAN:
  * ["Autoencoding beyond pixels using a learned similarity metric" Anders Boesen Lindbo Larsen, Søren Kaae Sønderby, Hugo Larochelle, Ole Winther. 2015](https://arxiv.org/abs/1512.09300)
 
## GANs.
* ["Generative Adversarial Networks" Goodfellow I, et al. 2014](https://arxiv.org/pdf/1406.2661.pdf)
* ["Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks" Radford A, et al. 2016](https://arxiv.org/abs/1511.06434)
* ["Improved Techniques for Training GANs" Salimans T, et al. 2016](https://arxiv.org/pdf/1606.03498v1.pdf)

* ["Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning" Miyato T, et al. 2017](https://arxiv.org/abs/1704.03976)
* ["Large Scale GAN Training for High Fidelity Natural Image Synthesis" Brock A, et al. 2018](https://arxiv.org/abs/1809.11096)
* ["Amortised MAP Inference for Image Super-resolution" Sønderby C, Caballero J, Theis L, Shi W, Huszár F. 2016](https://arxiv.org/abs/1610.04490)

* Conditional GANs:
  * ["Conditional Generative Nets" Mirza M, et al. 2014](https://arxiv.org/abs/1411.1784)
  * ["Conditional Image Synthesis With Auxiliary Classifier GANs" Odena A, et al. 2016](https://arxiv.org/abs/1610.09585)
  * ["Learning What and Where to Draw" Reed S, et al. 2016](https://arxiv.org/abs/1610.02454)
  * ["Stacked Generative Adversarial Networks" Huang X, et al. 2016](arxiv.org/abs/1612.04357)
  * ["StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks" Zhang H, et al. 2016](https://arxiv.org/abs/1612.03242)
 
* Cycle GANs:
  * ["Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks" Zhu J, et al. 2017](https://arxiv.org/abs/1703.10593)
  
* Least Squares GANs (LSGANs):
  * ["Least Squares Generative Adversarial Networks" Xudong Mao, Qing Li, Haoran Xie, Raymond Y.K. Lau, Zhen Wang, Stephen Paul Smolley. 2017](https://arxiv.org/abs/1611.04076)
 
* InfoGANS:
  * [" InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets" Chen X, et al. 2016](https://arxiv.org/abs/1701.07875)
  
* Wassertein GANs (WGANs): 
  * ["Wassertein GAN" Arjovsky M, et al. 2017](https://arxiv.org/abs/1701.07875)
  * ["Improved Training of Wasserstein GANs" Gulrajani I, et al. 2017](https://arxiv.org/abs/1704.00028)

* Boundary Equilibrium GANs (BEGANs):
  * [" BEGAN: Boundary Equilibrium Generative Adversarial Networks" Berthelot D, et al. 2017](https://arxiv.org/abs/1703.10717)
  
* Progressive growing of GANs (ProGANs):
  * ["Progressive Growing of GANs for Improved Quality, Stability, and Variation" Karras T, et al. 2017](https://arxiv.org/abs/1710.10196)

* Self-Attention GAN:
  * ["Self-Attention Generative Adversarial Networks" Zhang H, et al. 2018](https://arxiv.org/abs/1805.08318)

## Autoregressive Models.
* ["Neural Autoregressive Distribution Estimation" Benigno Uria, Marc-Alexandre Côté, Karol Gregor, Iain Murray, Hugo Larochelle. 2016](https://arxiv.org/abs/1605.02226)
* ["RNADE: The real-valued neural autoregressive density-estimator" Benigno Uria, Iain Murray, Hugo Larochelle. 2014](https://arxiv.org/abs/1306.0186)
* ["MADE: Masked Autoencoder for Distribution Estimation" Mathieu Germain, Karol Gregor, Iain Murray, Hugo Larochelle. 2015](https://arxiv.org/abs/1502.03509)
* ["Pixel Recurrent Neural Networks" Aaron van den Oord, Nal Kalchbrenner, Koray Kavukcuoglu. 2016](https://arxiv.org/abs/1601.06759)
* ["Conditional Image Generation with PixelCNN Decoders" Aaron van den Oord, Nal Kalchbrenner, Koray Kavukcuoglu. 2016](https://arxiv.org/abs/1606.05328)
* ["PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications" Tim Salimans, Andrej Karpathy, Xi Chen, Diederik P. Kingma. 2017](https://arxiv.org/abs/1701.05517)
* ["WaveNet: A Generative Model for Raw Audio" Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, Koray Kavukcuoglu. 2016](https://arxiv.org/pdf/1609.03499.pdf)

## Normalizing Flows.
* ["Glow: Generative Flow with Invertible 1x1 Convolutions" Kingma D Dhariwal P. 2018](https://arxiv.org/abs/1807.03039)
* ["NICE: Non-linear Independent Components Estimation" Dinh L Krueger D Bengio Y. 2014](https://arxiv.org/abs/1410.8516)
* ["Density estimation using Real NVP" Dinh L Sohl-Dickstein J Bengio S. 2016](https://arxiv.org/abs/1605.08803)

* VAE and Normalizing Flows:
  * ["Improving Variational Auto-Encoders using Householder Flow" Tomczak J Welling M. 2016](https://arxiv.org/abs/1611.09630)
  * ["Flow-GAN: Combining Maximum Likelihood and Adversarial Learning in Generative Models" Grover A Dhar M Ermon S. 2017](https://arxiv.org/abs/1505.05770)

* GAN and Normalizing Flows:
  * ["Variational Inference with Normalizing Flows" Rezende D Mohamed S. 2015](https://arxiv.org/abs/1705.08868)

## Evaluation of Generative Models.
* ["A note on the evaluation of generative models" Theis L Oord A Bethge M. 2015](https://arxiv.org/abs/1511.01844)
* ["Pros and Cons of GAN Evaluation Measures" Borji A. 2018](https://http://arxiv.org/abs/1802.03446)
* ["Are GANs Created Equal? A Large-Scale Study" Mario Lucic, Karol Kurach, Marcin Michalski, Sylvain Gelly, Olivier Bousquet
. 2018](https://arxiv.org/abs/1711.10337)
* [Stanford CS236: Deep Generative Models: Evaluating Generative Models](http://cs236.stanford.edu/assets/slides/cs236_lecture11.pdf)





