{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leakyReLU(x, alpha):\n",
    "    return tf.maximum(alpha*x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, train_images, train_labels, test_images, test_labels, projection_data_path, validation=0.0, shuffle=True):\n",
    "        self.train_img = train_images\n",
    "        self.train_labels = train_labels\n",
    "        self.shuffle = shuffle\n",
    "        self.projection_data_path = projection_data_path\n",
    "        self.metadata_tsv = '%s/metadata.tsv' % projection_data_path\n",
    "        self.sprite = '%s/sprite_train_img.png' % projection_data_path\n",
    "        if self.shuffle:\n",
    "            idx = np.arange(len(self.train_img))\n",
    "            np.random.shuffle(idx)\n",
    "            self.train_img = self.train_img[idx]\n",
    "            self.train_labels = self.train_labels[idx]\n",
    "        \n",
    "        whole_train = len(train_images)\n",
    "        num_validation_samples = int(whole_train*validation)\n",
    "        num_train_sample = whole_train - num_validation_samples\n",
    "        \n",
    "        self.train_img = self.train_img[:num_train_sample,:,:]\n",
    "        self.train_img = self.prepare_data(self.train_img)\n",
    "        self.train_labels = self.train_labels[:num_train_sample]\n",
    "        \n",
    "        self.test_img = self.prepare_data(test_images)\n",
    "        self.test_labels = test_labels\n",
    "        \n",
    "        if not validation == 0.0:\n",
    "            self.validation_labels = self.train_labels[num_train_sample+1:]\n",
    "            self.validation_img = self.train_img[num_train_sample+1:,:,:]\n",
    "            self.validation_img = self.prepare_data(self.validation_img)        \n",
    "            if len(self.train_img.shape)==3:\n",
    "                new_shape = self.validation_img.shape + (1,)\n",
    "                self.validation_img = self.validation_img.reshape(new_shape)\n",
    "\n",
    "        \n",
    "        if len(self.train_img.shape)==3:\n",
    "            new_shape = self.train_img.shape + (1,)\n",
    "            self.train_img = self.train_img.reshape(new_shape)\n",
    "            new_shape = self.test_img.shape + (1,)\n",
    "            self.test_img = self.test_img.reshape(new_shape)\n",
    "        \n",
    "        self.data_shape = self.train_img.shape\n",
    "        \n",
    "    def normalize(self, images):\n",
    "        # Normalize.\n",
    "        max_value = np.amax(images)\n",
    "        post = images/max_value\n",
    "        return post\n",
    "    \n",
    "    # Function to pre-process the data.\n",
    "    def prepare_data(self, images):\n",
    "        post_images = self.normalize(images)\n",
    "        return post_images\n",
    "    \n",
    "    def batches(self, batch_size):\n",
    "        n_batches = self.train_img.shape[0]//batch_size\n",
    "        for index in range(0, n_batches):\n",
    "            x = self.train_img[index:index+batch_size, :, :, :]\n",
    "            y = self.train_labels[index:index+batch_size]\n",
    "            yield (x, y)\n",
    "\n",
    "    def random_test(self):\n",
    "        idx = np.arange(len(self.test_img))\n",
    "        np.random.shuffle(idx)\n",
    "        return [self.test_img[idx[0], :, :]]\n",
    "    \n",
    "    def random_train(self):\n",
    "        idx = np.arange(len(self.train_img))\n",
    "        np.random.shuffle(idx)\n",
    "        return [self.train_img[idx[0], :, :]]\n",
    "    \n",
    "    def create_sprite_image(self, images):\n",
    "        if os.path.isfile(self.sprite):\n",
    "            os.remove(self.sprite)\n",
    "\n",
    "        img_h = images.shape[1]\n",
    "        img_w = images.shape[2]\n",
    "        n_plots = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "        spriteimage = np.ones((img_h * n_plots ,img_w * n_plots ))\n",
    "        for i in range(n_plots):\n",
    "            for j in range(n_plots):\n",
    "                this_filter = i * n_plots + j\n",
    "                if this_filter < images.shape[0]:\n",
    "                    this_img = images[this_filter]\n",
    "                    spriteimage[i * img_h:(i + 1) * img_h, j * img_w:(j + 1) * img_w] = this_img\n",
    "        plt.imsave(self.sprite, spriteimage,cmap='gray')\n",
    "\n",
    "    def create_tsv_file(self, img_labels):\n",
    "        if os.path.isfile(self.metadata_tsv):\n",
    "            os.remove(self.metadata_tsv)\n",
    "        \n",
    "        with open(self.metadata_tsv,'w') as f:\n",
    "            f.write(\"Index\\tLabel\\n\")\n",
    "            for index,label in enumerate(img_labels):\n",
    "                f.write(\"%d\\t%d\\n\" % (index,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to plot number images.\n",
    "def plot_images(plt_num, images, dim, cmap):\n",
    "    # Standard parameters for the plot.\n",
    "    \n",
    "    mpl.rcParams[\"figure.figsize\"] = dim, dim\n",
    "    fig = plt.figure()\n",
    "    for i in range(0, plt_num):\n",
    "        fig.add_subplot(1, 10, i+1)\n",
    "        img = images[i, :, :, 0]\n",
    "        plt.imshow(img, cmap=cmap)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAACBCAYAAABXearSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xv8TVX++PH3QlSSlIhpIkMZU7rQbcYkRammQkap1OiiMiOEiaYkzSS6TOk2KlITMkll6IYUNUWo3y9EoRS5NIzo5rq/f/i0rLU5xz7n7LPP3mu/no+HR+/9WfucvfL2Pp+Pbb/XUp7nCQAAAAAAANxWrtQTAAAAAAAAQPFxEwgAAAAAACAFuAkEAAAAAACQAtwEAgAAAAAASAFuAgEAAAAAAKQAN4EAAAAAAABSgJtAAAAAAAAAKVDQTSClVGul1CKl1GKlVN+wJoVokcfkI4duII/JRw7dQB6Tjxy6gTwmHzl0A3l0i/I8L78XKlVeRD4RkVYislxE3heRjp7nLQhveig28ph85NAN5DH5yKEbyGPykUM3kMfkI4duII/uqVDAa08UkcWe5y0VEVFKPSsiF4hIxj8MSqn87jihYJ7nqQxDOeWRHJbUfz3PO3g3X6cWE4RadAK16ABq0QnUogOoRSdQiw6gFp2QqRYthbSD/UxEvjSOl5d9DclCHpNjWYavk0M3kMfkoBbdRh6Tg1p0G3lMDmrRbeQxOTLVoqWQJ4ECUUp1EZEuxb4OioccuoE8Jh85dAN5TD5y6AbymHzk0A3kMfnIYbIUchNohYj83Dg+tOxrFs/zHhORx0R4NCym9phHchh71KIbqMXkoxbdQC0mH7XoBmox+ahFN1CLjimkHex9EWmglDpcKVVRRC4WkQnhTAsRIo/JRw7dQB6Tjxy6gTwmHzl0A3lMPnLoBvLomLyfBPI8b6tS6k8i8pqIlBeREZ7nzQ9tZogEeUw+cugG8ph85NAN5DH5yKEbyGPykUM3kEf35L1FfF4X49Gwksmy2ntOyGFJzfE8r2kYb0QeS4dadAK16ABq0QnUogOoRSdQiw6gFp0QqBaLvjA0EBdDhgyxjvv06aPjiRMnWmMdO3bU8bffflvciQEAAAAAEIFC1gQCAAAAAABAQnATCAAAAAAAIAVoB4NzKlasqON+/frp+IYbbrDO2759u45XrVpljW3ZsqVIswMAAADCddRRR1nHd9xxh47btGljjQ0dOlTHf/nLX3TMEghAOvAkEAAAAAAAQApwEwgAAAAAACAFuAkEAAAAAACQAs6uCXTiiSdax+edd56ODz30UB2fffbZ1nmvvPJKoPefNm2ajseMGWONsZ5MafXq1UvH/fv3z3jexo0bdfzEE09YY5s2bQp/YgCQQLVr19bx9OnTdTx27FjrvFtvvVXH5pprAPLTs2dP67hx48Y67ty5c9TTQUzstddeOv7jH/+o4z59+ljn1apVS8ee51lj3bp107G5DpC5PhAAd/EkEAAAAAAAQApwEwgAAAAAACAFEt0OVrlyZet40KBBOr7uuuussfXr1+t42LBhOvZvGz5r1iwdd+rUScfHHnusdd7IkSN1/Oabb1pjX3zxxR5mjjDVrVvXOu7YsWOg133//fc6njlzZphTApxy8sknW8fdu3fX8ZlnnqnjatWqWecppXQ8Y8YMHfsfWaf+4qV8+fLWcb169XYb9+vXzzrPbJOeMmVKkWYHpIf/5xtzCYM6deroeNmyZVFNCSXQsGFD63jw4ME6Npe7ABCtSpUq6di8v2DeQxCxWzPXrFlT/IkFwJNAAAAAAAAAKcBNIAAAAAAAgBRIXDuY2QL24osvWmNnnHGGjv27JkycOFHHa9euDXStO+64Q8dVq1a1xtq2bavjJk2aWGO0gxVfjRo1dDxu3Dhr7Fe/+tVuX7NkyRLrePXq1eFPLKX23ntv63j//fcP9LquXbvq2L9zxbPPPqtjs81o9uzZ1nlbt24NPE8E16NHDx37d9lbt26djt966y0dmzuMiIgccsghOm7ZsqWO33nnHeu8Sy+9VMf+HacQPTP3IiJ33313oNcNHz5cx+PHj7fGzB0YFy1apGPqNzwDBgzQ8W233WaN3X777To2W9j97eym0047LeNx0PdAuMyffVq1aqVj/w6nSB5/G27v3r117F/iwmwFzMb8e9Lo0aOtsccffzzXKQLwad++vY4vu+wyHfv/TvPZZ5/p2FxGQWTXn4mjwpNAAAAAAAAAKcBNIAAAAAAAgBTgJhAAAAAAAEAKKH/PWlEvplTBF6tZs6aOFy5caI0tX75cxyeddJI1Zm4Hng//VvJmv725Za6IyDfffFPQtYrB8zy157P2LIwchsFco+LGG28M9Bpzez6R+GzRl4M5nuc1DeONwsijuU7MWWedZY356y/LPHQc9LPo9ddft47NNbgefPBBa2z+/PmB3jNKca3F+vXrW8cffPCBjs1tL0VEbr31Vh3/8MMPGd/TzO8xxxyj4wsvvNA6z1z74Morr7TGxowZk23apRKrWgxDhQo7lwh8/vnnrbGwtyA2v38OGjTIGotyjaC41mK+ovx5zmTWeQk4V4smc0t4EZFJkybp2Pxcvv766yObUzG4Vov5MNftErG/zwb1wgsvWMfm+qgbNmywxlq0aKHjFStW6PiTTz7J+bplnK7FMGRbZ83kX9PNXHfNzFsxUIvZValSxTp+4403dHzcccdlfN369et1fPTRR1tjK1euDGl2WqBa5EkgAAAAAACAFOAmEAAAAAAAQAokrh3M5N8G3tye9r777rPGHnnkER0vXbo052v5W1DMVpj33nsv5/eLmguP93Xs2FHHI0aM0HHFihUDvZ52sJ3CyOO2bdt0nO/nSD7tYNnew/+48wUXXKDj6dOn5/X+YYtrLR577LHWsfm51qxZM2ts9uzZYV7aavny12mmx6VLLFa1GIYjjjhCx/5Wa9PmzZt1vH379oznlStn/xtTps/pcePGWcdmW8vatWszvn8Y4lqL+SpVO5i/PSHiLeOdq0WTv013zpw5Oja/9zVs2NA676uvviruxELmWi1mU7duXR2bP8v66yhbPZs/65jLVZhbwvvPi4DTtZiN+XOK/2cWf2tXofyfr2G3h6WpFvNhLm0gYn8mmxYsWGAdm3nzLzFTBLSDAQAAAAAAYAduAgEAAAAAAKQAN4EAAAAAAABSoMKeT4mvJ5980jq++OKLdezfNrx58+Y6njhxoo7vv/9+67xM27v7t2qcOXNmbpNFzlq2bGkdP/TQQzoOug7QyJEjdWxuz4fCmX2x/nULqlWrpmN/nebD3ILeXOdHROSiiy7S8QEHHGCN/etf/9LxIYccUvA8XPbhhx9ax+a2l0OGDLHGrrvuOh0XsJ2sNmvWLB3784totGnTJtB5AwYM0PHXX39tjf3mN7/Rsf/P0+DBg3VcqVIlHbdv394676OPPtJxKbePTyJzjZhsWxGHvUYFimfx4sXWsbkF+OWXX65j/1by5hqZKC1zDSARkVdffVXH5lps2bz//vvW8Z133qnjl156Kf/JITDze59I6T5HY7pOYmqYP//6mesA+f8OG8d1aPf4JJBSaoRSao1Sap7xtQOVUpOVUp+W/bdatvdA6ZFHJ9Qlh8lHLTqBWnQAtegEatEB1KITqEUHUIvpEaQdbKSItPZ9ra+ITPU8r4GITC07RryNFPKYdP8VcuiCkUIek45adMNIIY9JRy26YaSQx6SjFt0wUshjKgTaIl4pVVdEJnqed1TZ8SIROc3zvJVKqVoi8qbneUcGeJ+ibhdnbkl7ySWXWGPt2rXTsdluMHfuXOu8P//5zzqeNm1awXM6+OCDdex/dD5KnuepMPIY5ZZ/nTp1so7N1q5szLav888/X8fvvPNOKPMqoTki0l4SUIvF5G89M+vUv724WXP+sVJJSi2a7QX/+Mc/rLElS5bouHfv3jr2f54GZbb7DRw40BpbtGiRjo877jgd33fffdZ5YbQd5sCJWjS/P5kteXXq1LHO+/HHH3XcuvXOnw2nT58e+Fpnnnmmjs02LzOnfrVr17aOV61aFfh6QSSlFosp3xaH22+/PeN7RMyJWgzK/L3u37+/jkeNGmWd5//5Ke5cq8W+fXf+Hblnz57WmPm5a9q2bZt1/Oijj+r4lltuscYi3vo9qEhqMdt27CZzGRD/eebnl18x27z827u/9dZbOjZrO8jfzX9itgGHwbVaDIO57MTo0aOtsc2bN+u4SZMmOvZvER+xom4RX9PzvJVl8SoRqZnn+6C0yGPykUM3kMfkI4duII/JRw7dQB6Tjxy6gTw6qOCFob0dtwwz3u1TSnURkS6FXgfFlS2P5DAZqEU3UIvJRy26gVpMPmrRDdRi8lGLbqAW3ZHvTaDVSqlaxmNhGZe89jzvMRF5TKT4j4Zt375dx88884w1Zh6feuqpOr755put81588UUdjxs3Tsf+XUq++OILHV977bXW2IUXXqjjmjV33iw1d04REVm3bt1u/i8iFSiPUebQ1Lhx47xed/XVV+vYgRawPYllLYbN3A3O3PFLxG4Z8T9Cm0u7SonFrhZfeeUVHZ9zzjnW2Msvv6zj//znPzq+/vrrrfMytWjts88+1rHZonvCCSdYY9WrV9ex2Srm/3MQA4mrxcqVK+vY3wJmMh9rzremXn/9dR0feOCBOvY/Wm3q0KGDdTx06NC8rp2j2NViMZktE3sSoxawPUlcLQa1cePG3X69SpUqEc8kEomqxZtuuknH5veqChWC/VXL/3ln7gSXYKHXYhhLdYTd8pWtvSzoZ2XQXb/8LWURSVQths1sx/T/PcOs+xK3gOUs33awCSJyRVl8hYiwP2EykcfkI4duII/JRw7dQB6Tjxy6gTwmHzl0A3l0UJAt4seIyLsicqRSarlS6ioRuUtEWimlPhWRlmXHiDHy6ITDhRwmHrXoBGrRAdSiE6hFB1CLTqAWHUAtpscen1H0PK9jhqEzQp4Liog8OuGzDKu9k8MEoRadQC06gFp0ArXoAGrRCdSiA6jF9Ch4YegkMtc0eO+996yxLl12rmdlbkHs327zgw8+0LF/DQtzW0dzq/oYrAGUKH/6058CnWeuTyIi8vbbbxd8bXMLz65du+p47dq11nnmehbkN1zmOkAPP/ywjrOtFfXuu+9ax5dffnn4E0uh+fPnW8e//e1vdWx+Tvq3kj/ssMN0fO+99+r4nnvusc7r3Lmzjv1bHffr10/Hy5cvz2XaiCnzc3TTpk3WWKVKlXTcoEGDyObkgly2FS5UtnUuzDUrSrR+hbOefvppHffq1UvH559/vnVew4YNdbxw4cLiTywlDjnkEB3715W55pprdFyuXLDVNtq1a6djc01SZGZ+pgRdRycXmdb38X+Whf3ZFnStoxYtWoR6Xeyqd+/e1nGjRo10vGTJEmvM/zNrkuS7JhAAAAAAAAAShJtAAAAAAAAAKaCifHw4advFmVu6z5gxI+N569evt46PP/54HX/++eehzysfnuepMN4nyhz+8MMP1rHZHmSqVq2adbxhw4ZA77/ffvvpuEePHtbYjTfeqOOqVatmfA8zv+Y21yIi8+bNCzSPHMzJ0G+dsyTUovnI6+TJkzOeZ9affyvzWbNmhT+xAiWxFrPZe++9dezfIn7IkCE6/vrrr3Vco0YN67xLL71Ux2PHjg17isXgRC3WrVtXx0uXLs143ty5c3XctGko/9vaJ598Yh3Xr19fx2YbqIhIt27dQr22a7UY5c9zQflbF4rQHuZELeZjzJgxOr7oooussf79++v4r3/9a2Rzyldca9Hf1mW24Jnf37LxLzvRqlUrHX/77bcFzC52Sl6LZpuq2a7nb/GKY8tq0M9vpUIplWzziGUtRumrr76yjmvWrKlj8zNAROT++++PZE45ClSLPAkEAAAAAACQAtwEAgAAAAAASIFU7g6WjfkouvnI1+bNm63zzB3ArrzySmts0qRJOu7QoYOO/TvsYFfmI5t77bVXxvPMFoJt27YFem9/C8rw4cN17G8jCspspzj22GOtsSK0gznNbKMUEZk4caKOsz3+araIxLH9y3U//vijjh955BFr7IorrtCxuavbqlWrrPPmzJlTpNkhGzM/pu+++846Nnd2C5u525GIyMCBA4t2LdeZ3z+bN2+e8bxi7KgT9Fpxab1wgbkbpr8d7Ne//nXU03GSv8V58ODBOs7WvmPuUnveeedZY2YLmLnbmL918pRTTsltsrvx8ccf69jczVZE5Jtvvin4/ePGbAfLtoNhXASdI5+bxXfXXXfpuHr16taYuQu1fxfcJONJIAAAAAAAgBTgJhAAAAAAAEAKcBMIAAAAAAAgBVgTyKd79+46btOmjY4ffPBB67yePXvq+IUXXrDGXnrpJR1PmTJFx127drXO878O9nbv2daBeeKJJ3TsX78iE3MNIJH81wHKZJ999gn1/dLGrCkRkUqVKunY7L33r09ibpOL0jK3JRYRqVKlio4vueQSHR966KHWeQsXLtTxa6+9Zo2Zn8mLFy8OZZ5pdfLJJ1vH/u9JP5k8ebJ1XMwa++KLL4r23mkTdH2JoFsR+9ehCLqWkPm6JKzLkVTPPfecjv3bFP/yl7/U8b777muNff/998WdWMJVqLDzr0b+dXqymT59uo7N9dZatmxpnXfuuefq+LLLLtOxfx3MoHUalP9nrBNOOEHHLq4PFEf+z1BzG/ts/FvcIxxt27bVcZ8+fTKeZ/7+m+tgJh1PAgEAAAAAAKQAN4EAAAAAAABSIPXtYGeddZZ13KVLFx3PmDFDx+Z28X7mI6Ai9iOX5iO6Dz/8sHWe+cip+Vgv9uzUU0/V8UMPPWSNbdq0abevadq0aVHn5H8c+/HHHy/q9VzQqVMnHbdv3z7jeVu2bNGxv60PpWU+TnvTTTdZY+Z2us8++2zG9/jyyy91PGTIEGvMbK81H1+npSF3Zr2JiBx88MG7PW/s2LFRTEdERK6++urIrpVmQduyzMfeg76GbeBLY82aNTqeNGmSNWa2HF111VXWmH95A4iUL19ex7fccouO27Vrl/E1ZhuziMiVV16p4wceeEDH559/fsb3WL16tY5XrVpljeXTDtagQQPruHLlyjquX7++NWa2aD/66KM5Xwu5C9pS62//4jM1HE2aNLGOhw4dqmOz3p566inrvNmzZxd3YiXCk0AAAAAAAAApwE0gAAAAAACAFOAmEAAAAAAAQAqkck0gs/e3Q4cO1li5cjvvi5lbPG7dujXw+48cOVLHn332mY5ffvll67xu3brp2L9dfC7XS6Pf/e53Oja3Ehex1wQy12c66KCDij8x5OTEE0/UsX97VNOCBQt0vGLFiqLOCbmpV6+ejrdt22aN+T/XMjHXoFmyZIk1Zq7NZq4r1LFjR+u87777LtC1UHpnn322js3PAJRePmtPsF5FaZift/51vMyfkcy1X0RYE2h39t13Xx33798/43nm95k77rjDGjvyyCN1nG0doJkzZ+rYXBNt/vz5wSabhbmuqYjIwIEDdVyjRg1rrGHDhgVfD7kJuiU8n6nhMf+OOGjQIGusVq1aOp46daqOr7/++uJPLAZ4EggAAAAAACAFuAkEAAAAAACQAqlsBzMf0+zcubM1Nn78eB1//vnnBV/rrbfe0vGECROssYsuukjHjzzyiDXmf6QzLZ5++mkdX3vttdZYhQq7/+M6bNgw69jcTvyYY47RsdkGWAxsXV48Zh4/+OADa2zKlCk6/uijj6wxszXzhx9+KM7koC1btsw6zmdbTf9rzG13R4wYoeMnn3zSOs/f2ot4Oeyww3Q8ePBgHVesWDHja+bNm1fUOYGtiF1lbndcvXp1a6xKlSo63rhxY2RzcsGnn36q4zFjxlhjo0eP3u1rJk2aZB1feOGFOt68eXNe89h///11fPHFF+t4yJAhGc/z++c//5nXtZGbadOmBTrP/Ozlczg811xzjY5PP/10a2zlypU67tevn47zrcuk4UkgAAAAAACAFOAmEAAAAAAAQAqksh2sZcuWOt6+fbs1VsyWHv9OAhdccIGODz/88KJdN0nMVhCzzUdEpHXr1rt9TSnbQL766isdm61sCMbcIc/fSnTnnXfq2Gzl+8UvfmGd16BBAx376/mhhx4KNI/169frONMj3Xti/r+k1apVq0J/T/ORe3MHF38L7aWXXqrjUaNGhT4P5Mb8/iZif/876qijMr6ub9++On7iiSfCn1hKBd2VBsn0zDPPWMfm7jannHKKNdauXTsdP/XUU8WdWEKYbcf5Mn8GNH9mMX+WEcncauLfIbVt27Y6Pvfcc62xk046ScdHHHGEjv3fgx944AEd+3frDGM3MuzZaaedFug8f2suwmHWgNkmK2IvKzB37tzI5hQXPAkEAAAAAACQAnu8CaSU+rlSappSaoFSar5SqnvZ1w9USk1WSn1a9t9qxZ8u8kUOnbAXeUw+cugEatEB5NAJ1KIDyKETqEUHkMP0CPIk0FYR6eV5XiMROVlE/qiUaiQifUVkqud5DURkatkx4oscuoE8Jh85dAN5TD5y6AbymHzk0A3kMfnIYUrscU0gz/NWisjKsnijUupjEfmZiFwgIqeVnfaUiLwpIjcVZZZF5N82+uOPPy7atRYsWGAdf/jhhzpu0qSJNVajRg0dr1mzpuBre543t+y/icmhfz2X2rVr67hx48ZFvfY333yj40WLFun4tddes84ze8CXLl1a1DmJyJYk5jGoe+65xzo2t4I3t3g866yzrPPMLVD9/b5BHXDAATo211LIZsmSJXldy+Uc+j/H6tWrp+Mw6sNc6+emm+zfHnMtmQjWBHKiFpVSOjZrp1WrVtZ577//vo7NPPrX/WnWrJmOb7jhBmvMv97FT/y5MtcB2rZtW8a5h8GFHGYyYMCAUk8hKk7UYtjuvvtuHY8fP94aM7coj8uaQKXOofl79Pe//z3jeY0aNdLxG2+8YY2ZW66/+uqrOj7++OOt88zjPn366Hjvvfe2zqtbt27Geaxbt07H5nprw4YNs84z162MALVYgLhsC5/EHO6zzz7W8bhx43RcrtzO513M9YFERPr371/cicVcTgtDK6XqishxIjJTRGqW3SASEVklIjUzvKaLiHTJf4oIEzl0A3lMPnLoBvKYfOTQDeQx+cihG8hj8pFD9wVeGFoptZ+IPC8iPTzP22COeTv+CXG3/wTved5jnuc19TyvaUEzRcHIoRvIY/KRQzeQx+Qjh24gj8lHDt1AHpOPHKZDoCeBlFJ7yY4/DKM8z/vpmcnVSqlanuetVErVEpHCe5ZKoHLlytax2d5jPqY5c+bMgq/lb5WoX7++jufMmWONhdECZkpiDl955RXr+N1339Wx+TizX48ePXRsPrrrt2HDzs+13r17W2MrVqzQsflYb6klMY/5mjp16m7jatXs9egqVNj5MeZvTzFbCLPJ1BYjIvLjjz/q2NxO0t9KGpRrOXz++ed13L17d2usZ8+eOu7WrVvB1zJz8e9//9sa69ChQ8Hvn4sk5nHWrFnWcabWR/92yebv7ZYtW3RcpUoV6zyzFrPp16+fjv1toMVuATMlMYfYFXnc1bx583Ts/15lbhnfsGFDHS9cuLD4E8ug1Dk0f+YePny4jq+66irrvIoVK+rYv/V30K3AM3nvvfesY/N73MSJE60xczvrtWvXFnTdMJU6j3GQy5+DOG4Ln8Qctm/f3jo2l43YvHmzjidPnhzZnJIgyO5gSkSGi8jHnufdZwxNEJEryuIrROSl8KeHEJFDN5DH5COHbiCPyUcO3UAek48cuoE8Jh85TIkg/2z3GxHpJCIfKaV+Wsn4ZhG5S0T+pZS6SkSWiUi0/wyLXJHD5NtPyKMLyGHyUYtuIIfJRy26gRwmH7XoBnKYEkF2B3tbRFSG4TPCnQ6KxfM8cph835LH5COHTqAWHUAOnUAtOoAcOoFadAA5TI+cdgdzhbn9o7kVu4jdVzh9+nQdr169OuP7mdvnitjbIh900EE6rlq1asb3mDFjRpYZQ0Rk/fr1OjZ7tv2yjSH5/ve//2UcM7eXRjQ+//xzHftr79Zbb9WxuYaBubZSLmrVqqXj008/3Roz+76xe+YWxiL2lsSPPvpoxtftt99+OV/L3EpeRKR169a7Hdu+fXvO7w0gu8WLF+t47Nix1tgf/vAHHV933XU6NtdTTJtNmzbp+Nprr9XxlClTrPNatWqlY//aaUHNnj1bx+aaMP71SvielkyFrg2F3GVbJ/bmm2/W8aRJk6KYTmIE3h0MAAAAAAAAycVNIAAAAAAAgBRIZTuY+ZjsJZdcYo1NmDBBxy1atNCxuZ27iMhhhx2m47Zt22a8lrnVuLmVsojdOvHOO+/sadoAEGsjRoywjs3th//2t7/puFmzZtZ5b7/9to79LbqZPoerVatmnXfuuefmMeN08bdePfbYYzpet26djo8++mjrvN///vc6PvLII3U8atQo6zyztcFsExQR2bp1a+4TRt5uu+22Uk8BMTFs2DDr2GwHW7ZsWcSziT/zc9LfSmceX3311ZHNCcnRvHnzUk8hderUqZNx7N57741wJsnCk0AAAAAAAAApwE0gAAAAAACAFFCe50V3MaWiuxgsWbb8ywk5LKk5nuc1DeONyGPppKkWy5cvr+OuXbvquFevXtZ5Znut39q1a3X83HPP6Xjo0KHWeQsXLsx7nnmgFh3gci0G/dnObLcUEXnzzTeLMJuiohYd4HItpkhqa3HAgAE6zqUV12yhNt+jlJJYi48//rh13LlzZx0vWLBAx40bN45qSqUWqBZ5EggAAAAAACAFuAkEAAAAAACQAtwEAgAAAAAASIFUbhEPACi+bdu26fjBBx/cbQwgfOZaE37muj8JXAMIAJzA5284rrnmmqzH2D2eBAIAAAAAAEgBbgIBAAAAAACkAO1gAAAADonLdsMA4DqzrSvbFvH+Nl3awVBKPAkEAAAAAACQAtwEAgAAAAAASAFuAgEAAAAAAKQAawIBAAAAAJAjc20fpVTpJgLkgCeBAAAAAAAAUoCbQAAAAAAAACkQdTvYf0VkmYhUL4tLKQ5zEIlmHnW6hdlDAAAEJUlEQVRCfK845VAkXfMIO4/fSXp+74JIYg6pxV0lMY/Uoi2JOaQWd5XEPFKLtiTmkFrcVRLzSC3akphDarE0cwiUR+V5XrEnsutFlZrteV7TyC8csznEaR65isu8mUf+4jJn5lGYuMybeeQvLnNmHoWJy7yZR/7iMmfmUZi4zJt55C8uc2YehYnLvOMwjzjMwUQ7GAAAAAAAQApwEwgAAAAAACAFSnUT6LESXdcUhzmIxGceuYrLvJlH/uIyZ+ZRmLjMm3nkLy5zZh6Ficu8mUf+4jJn5lGYuMybeeQvLnNmHoWJy7zjMI84zEEryZpAAAAAAAAAiBbtYAAAAAAAACkQ6U0gpVRrpdQipdRipVTfCK87Qim1Rik1z/jagUqpyUqpT8v+Wy2CefxcKTVNKbVAKTVfKdW9VHMpRJrzSA4Lvi45DEmpclh2bfIYEmqRHBZ4bfIYEmqRHBZ4bfIYEmqRHBZ4bfIYhOd5kfwSkfIiskRE6olIRRH5fyLSKKJrnyoix4vIPONrQ0Skb1ncV0QGRzCPWiJyfFlcRUQ+EZFGpZgLeSSH5JAcksf05pEcJj+H5NGNPJLD5OeQPLqRR3KY/BySxxzmGGFCThGR14zjfiLSL8Lr1/X9YVgkIrWMRC2K/Ddf5CURaRWHuZBHckgOySF5TFceyWHyc0ge3cgjOUx+DsmjG3kkh8nPIXkM9ivKdrCficiXxvHysq+VSk3P81aWxatEpGaUF1dK1RWR40RkZqnnkiPyWIYchoYc5i5uORQhj/mIWx7JYe7ilkMR8piPuOWRHOYubjkUIY/5iFseyWHu4pZDEfK4CxaGFhFvx+04L6rrKaX2E5HnRaSH53kbSjkXl0T5e0cOi4McuoE8Jh85dAN5TD5y6AbymHzk0A3kcYcobwKtEJGfG8eHln2tVFYrpWqJiJT9d00UF1VK7SU7/jCM8jxvfCnnkqfU55Echo4c5i5uORQhj/mIWx7JYe7ilkMR8piPuOWRHOYubjkUIY/5iFseyWHu4pZDEfK4iyhvAr0vIg2UUocrpSqKyMUiMiHC6/tNEJEryuIrZEevXlEppZSIDBeRjz3Pu6+UcylAqvNIDouCHOYubjkUIY/5iFseyWHu4pZDEfKYj7jlkRzmLm45FCGP+YhbHslh7uKWQxHyuKsoFyASkXNkx+rYS0TkLxFed4yIrBSRLbKjL/EqETlIRKaKyKciMkVEDoxgHs1kx2Nf/19EPiz7dU4p5kIeySE5JIfksfS/qEVySB7j8YtaJIfkMR6/qEVySB6L/0uVTRQAAAAAAAAOY2FoAAAAAACAFOAmEAAAAAAAQApwEwgAAAAAACAFuAkEAAAAAACQAtwEAgAAAAAASAFuAgEAAAAAAKQAN4EAAAAAAABSgJtAAAAAAAAAKfB/QRk0V0AkWdYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()\n",
    "projection_data_path = '/Users/adalbertoclaudioquiros/Documents/Code/UofG/PhD/GANs'\n",
    "data = Dataset(train_images, train_labels, test_images, test_labels, projection_data_path, validation=0.0, shuffle=True)\n",
    "\n",
    "plot_images(plt_num=10, images=data.train_img, dim=20, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inputs(image_width, image_height, image_channels, z_dim):\n",
    "    real_images = tf.placeholder(dtype=tf.float32, shape=(None, image_width, image_height, image_channels), name='real_images')\n",
    "    z_input = tf.placeholder(dtype=tf.float32, shape=(None, z_dim), name='z_input')\n",
    "    learning_rate = tf.placeholder(dtype=tf.float32, name='learning_rate')\n",
    "    return real_images, z_input, learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(images, reuse, alpha):\n",
    "    \n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        \n",
    "        # Padding = 'Same' -> H_new = H_old // Stride\n",
    "        \n",
    "        # First layer: Conv2d -> LeakyReLU\n",
    "        # Input Shape: (28, 28, 1)\n",
    "        # Output Shape: (16, 16, 64)\n",
    "        c1 = tf.layers.conv2d(inputs=images, filters=64, kernel_size=(5,5), strides=(2, 2), padding='same', \n",
    "                              kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(), name='c1')\n",
    "        leaky_c1 = leakyReLU(c1, alpha)\n",
    "        \n",
    "        # Second layer: Conv2d -> BN -> LeakyReLU\n",
    "        # Input Shape: (16, 16, 64)\n",
    "        # Output Shape: (8, 8, 128)\n",
    "        c2 = tf.layers.conv2d(inputs=leaky_c1, filters=128, kernel_size=(5,5), strides=(2, 2), padding='same', \n",
    "                              kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(), name='c2')\n",
    "        bc2 = tf.layers.batch_normalization(c2, training=True)\n",
    "        leaky_c2 = leakyReLU(bc2, alpha)\n",
    "\n",
    "        flatten = tf.layers.flatten(leaky_c2, name='flatten')\n",
    "\n",
    "        # Dense.\n",
    "        fully1 = tf.layers.dense(flatten, 1024, activation=None)\n",
    "        bn_fully1 = tf.layers.batch_normalization(fully1, training=True)\n",
    "        leaky_fully1 = leakyReLU(bn_fully1, alpha)\n",
    "        \n",
    "        # Dense\n",
    "        logits = tf.layers.dense(leaky_fully1, 1, activation=None)\n",
    "        output = tf.nn.sigmoid(logits)\n",
    "        \n",
    "        return output, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z_input, out_channel_dim, reuse, is_train, alpha):\n",
    "    \n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        \n",
    "        # Fully\n",
    "        fully1 = tf.layers.dense(inputs=z_input, units=1024, activation=None)\n",
    "        bn_fully1 = tf.layers.batch_normalization(fully1, training=is_train)\n",
    "        leaky_bfc1 = leakyReLU(bn_fully1, alpha)\n",
    "        \n",
    "        # Fully\n",
    "        fully2 = tf.layers.dense(inputs=leaky_bfc1, units=128*7*7, activation=None)\n",
    "        bn_fully2 = tf.layers.batch_normalization(fully2, training=is_train)\n",
    "        leaky_bfc2 = leakyReLU(bn_fully2, alpha)\n",
    "        \n",
    "        fc_reshape = tf.reshape(leaky_bfc2, (-1, 7, 7, 128))\n",
    "        \n",
    "        # Conv\n",
    "        c1 = tf.layers.conv2d_transpose(inputs=fc_reshape, filters=128, kernel_size=(5,5), strides=(2,2), padding='same', \n",
    "                              kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(), name='c1')\n",
    "        bc1 = tf.layers.batch_normalization(c1, training=is_train)\n",
    "        leaky_c1 = leakyReLU(bc1, alpha)\n",
    "        \n",
    "        # Conv\n",
    "        c2 = tf.layers.conv2d_transpose(inputs=leaky_c1, filters=128, kernel_size=(5,5), strides=(1,1), padding='same', \n",
    "                              kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(), name='c2')\n",
    "        bc2 = tf.layers.batch_normalization(c2, training=is_train)\n",
    "        leaky_c2 = leakyReLU(bc2, alpha)\n",
    "        \n",
    "        # Conv\n",
    "        logits = tf.layers.conv2d_transpose(inputs=leaky_c2, filters=out_channel_dim, kernel_size=(5,5), strides=(2,2), \n",
    "                                            padding='same', kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(), \n",
    "                                            name='logits')\n",
    "        output = tf.nn.sigmoid(logits, name='output')\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_generated(session, output_fake, n_images, z_input, image_type):\n",
    "    cmap = None if image_type == 'RGB' else 'gray'\n",
    "    z_dim = z_input.get_shape()[-1]\n",
    "    sample_z = np.random.uniform(low=-1., high=1., size=(n_images, z_dim))\n",
    "    feed_dict = {z_input:sample_z}\n",
    "    gen_samples = session.run(output_fake, feed_dict=feed_dict)\n",
    "    \n",
    "    gen_samples *= 255.\n",
    "    \n",
    "    plot_images(plt_num=n_images, images=gen_samples, dim=10, cmap=cmap)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining new cost function according to WGAN.\n",
    "# Loss(Lpr, Lpg) = Max-w ( Ex~pr[fw(x)] - Ez~pg(z)[fw(Gtheta(z))] )  \n",
    "\n",
    "# Generator would want to find the theta parameters that minimizes the cost of moving the distributions.\n",
    "# Discriminator/Critic wants to find the w parameters that approximate better the Wassertein distance. Find maximum \n",
    "# of the moving the distribution Pg to Pr.\n",
    "\n",
    "\n",
    "def loss(real_images, z_input, out_channel_dim, alpha):\n",
    "    \n",
    "    # Generator.\n",
    "    fake_images = generator(z_input, out_channel_dim=out_channel_dim, reuse=False, is_train=True, alpha=alpha)\n",
    "    \n",
    "    # Discriminator.\n",
    "    output_fake, logits_fake = discriminator(images=fake_images, reuse=False, alpha=alpha) \n",
    "    output_real, logits_real = discriminator(images=real_images, reuse=True, alpha=alpha)\n",
    "    \n",
    "    # Discriminator loss.\n",
    "    loss_dis_real = tf.reduce_mean(logits_real)\n",
    "    loss_dis_fake = tf.reduce_mean(logits_fake)\n",
    "    loss_dis = -(loss_dis_real - loss_dis_fake)\n",
    "\n",
    "    # Generator loss.\n",
    "    # This is where we implement -log[D(G(z))] instead log[1-D(G(z))].\n",
    "    # Recall the implementation of cross-entropy, sign already in. \n",
    "    loss_gen = -loss_dis_fake\n",
    "    \n",
    "    return loss_dis, loss_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining new cost function according to WGAN. \n",
    "Loss(Lpr, Lpg) = Max-w ( Ex~pr[fw(x)] - Ez~pg(z)[fw(Gtheta(z))] )  \n",
    "Generator would want to find the theta parameters that minimizes the cost of moving the distributions.\n",
    "Discriminator/Critic wants to find the w parameters that approximate better the Wassertein distance. Find maximum \n",
    "of the moving the distribution Pg to Pr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization(loss_dis, loss_gen, learning_rate, c):\n",
    "    trainable_variables = tf.trainable_variables()\n",
    "    generator_variables = [variable for variable in trainable_variables if 'generator' in variable.name]\n",
    "    discriminator_variables = [variable for variable in trainable_variables if 'discriminator' in variable.name]\n",
    "    \n",
    "    # Handling Batch Normalization.\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        \n",
    "        RMS_optimizer_dis = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\n",
    "        train_discriminator = RMS_optimizer_dis.minimize(loss_dis , var_list=discriminator_variables)\n",
    "        \n",
    "        # Weight Clipping on Discriminator, this is done to ensure the Lipschitz constrain.\n",
    "        dis_weight_clipping = [value.assign(tf.clip_by_value(value, -c, c)) for value in discriminator_variables]\n",
    "        \n",
    "        train_discriminator = tf.group(*[train_discriminator, dis_weight_clipping])\n",
    "        \n",
    "        # Generator.\n",
    "        RMS_optimizer_gen = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\n",
    "        train_generator = RMS_optimizer_gen.minimize(loss_gen, var_list=generator_variables)\n",
    "        \n",
    "    return train_generator, train_discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, batch_size, z_dim, learning_rate, dataset, image_type, alpha, n_critic, c):\n",
    "    \n",
    "    dataset_size, image_width, image_height, image_channels = dataset.data_shape\n",
    "    \n",
    "    inputs = model_inputs(image_width=image_width, image_height=image_height, image_channels=image_channels, z_dim=z_dim)\n",
    "    real_images, z_input, learning_rate_input = inputs\n",
    "    \n",
    "    loss_dis, loss_gen = loss(real_images=real_images, z_input=z_input, out_channel_dim=image_channels, alpha=alpha)\n",
    "    \n",
    "    train_generator, train_discriminator = optimization(loss_dis=loss_dis, loss_gen=loss_gen, learning_rate=learning_rate_input, c=c)\n",
    "    \n",
    "    output_gen = generator(z_input=z_input, out_channel_dim=image_channels, reuse=True, is_train=False, alpha=alpha)\n",
    "\n",
    "    losses = list()\n",
    "    run_epochs = 0\n",
    "    \n",
    "    show_epochs = 100\n",
    "    print_epochs = 10\n",
    "    n_images = 10\n",
    "    \n",
    "    critic_iterations = 0\n",
    "    \n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        for epoch in range(epochs+1):\n",
    "            get_batches = data.batches(batch_size)\n",
    "            for batch_images, batch_labels in get_batches:\n",
    "                \n",
    "                z_batch = np.random.uniform(low=-1., high=1., size=(batch_size, z_dim))\n",
    "                feed_dict = {z_input:z_batch, real_images:batch_images, learning_rate_input: learning_rate}\n",
    "                \n",
    "                # Update critic and clip gradients.\n",
    "                session.run(train_discriminator, feed_dict=feed_dict)\n",
    "                critic_iterations += 1\n",
    "                \n",
    "                # Update generator after n_critic updates from discriminator.\n",
    "                if n_critic == critic_iterations:\n",
    "                    critic_iterations = 0\n",
    "                    session.run(train_generator, feed_dict=feed_dict)\n",
    "               \n",
    "                # Print losses and Generate samples.\n",
    "                if run_epochs%print_epochs==0:\n",
    "                    feed_dict = {z_input:z_batch, real_images:batch_images}\n",
    "                    epoch_loss_dis = session.run(loss_dis, feed_dict=feed_dict)\n",
    "                    epoch_loss_gen = session.run(loss_gen, feed_dict=feed_dict)\n",
    "                    losses.append((epoch_loss_dis, epoch_loss_gen))\n",
    "                    print('Epochs %s/%s: Generator Loss: %s. Discriminator Loss: %s' % \n",
    "                          (epoch, epochs, np.round(epoch_loss_gen, 3), np.round(epoch_loss_dis, 3)))\n",
    "                if run_epochs%show_epochs == 0:\n",
    "                    show_generated(session, output_gen, n_images, z_input, image_type)\n",
    "                run_epochs+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(32, 100), b.shape=(100, 1024), m=32, n=1024, k=100\n\t [[node generator/dense/MatMul (defined at <ipython-input-8-282c9372cbdd>:6)  = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_z_input_0_2/_3, generator/dense/kernel/read)]]\n\nCaused by op 'generator/dense/MatMul', defined at:\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-dce87ebab920>\", line 18, in <module>\n    train(epochs, batch_size, z_dim, learning_rate, dataset, image_type, alpha, n_critic, c)\n  File \"<ipython-input-17-7ee067e8ac60>\", line 8, in train\n    loss_dis, loss_gen = loss(real_images=real_images, z_input=z_input, out_channel_dim=image_channels, alpha=alpha)\n  File \"<ipython-input-10-68402356bb80>\", line 12, in loss\n    fake_images = generator(z_input, out_channel_dim=out_channel_dim, reuse=False, is_train=True, alpha=alpha)\n  File \"<ipython-input-8-282c9372cbdd>\", line 6, in generator\n    fully1 = tf.layers.dense(inputs=z_input, units=1024, activation=None)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/layers/core.py\", line 184, in dense\n    return layer.apply(inputs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 817, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 374, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 757, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py\", line 970, in call\n    outputs = gen_math_ops.mat_mul(inputs, self.kernel)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4560, in mat_mul\n    name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(32, 100), b.shape=(100, 1024), m=32, n=1024, k=100\n\t [[node generator/dense/MatMul (defined at <ipython-input-8-282c9372cbdd>:6)  = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_z_input_0_2/_3, generator/dense/kernel/read)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(32, 100), b.shape=(100, 1024), m=32, n=1024, k=100\n\t [[{{node generator/dense/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_z_input_0_2/_3, generator/dense/kernel/read)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-dce87ebab920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_critic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-7ee067e8ac60>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, batch_size, z_dim, learning_rate, dataset, image_type, alpha, n_critic, c)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;31m# Update critic and clip gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_discriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mcritic_iterations\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(32, 100), b.shape=(100, 1024), m=32, n=1024, k=100\n\t [[node generator/dense/MatMul (defined at <ipython-input-8-282c9372cbdd>:6)  = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_z_input_0_2/_3, generator/dense/kernel/read)]]\n\nCaused by op 'generator/dense/MatMul', defined at:\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-dce87ebab920>\", line 18, in <module>\n    train(epochs, batch_size, z_dim, learning_rate, dataset, image_type, alpha, n_critic, c)\n  File \"<ipython-input-17-7ee067e8ac60>\", line 8, in train\n    loss_dis, loss_gen = loss(real_images=real_images, z_input=z_input, out_channel_dim=image_channels, alpha=alpha)\n  File \"<ipython-input-10-68402356bb80>\", line 12, in loss\n    fake_images = generator(z_input, out_channel_dim=out_channel_dim, reuse=False, is_train=True, alpha=alpha)\n  File \"<ipython-input-8-282c9372cbdd>\", line 6, in generator\n    fully1 = tf.layers.dense(inputs=z_input, units=1024, activation=None)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/layers/core.py\", line 184, in dense\n    return layer.apply(inputs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 817, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 374, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 757, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py\", line 970, in call\n    outputs = gen_math_ops.mat_mul(inputs, self.kernel)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4560, in mat_mul\n    name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(32, 100), b.shape=(100, 1024), m=32, n=1024, k=100\n\t [[node generator/dense/MatMul (defined at <ipython-input-8-282c9372cbdd>:6)  = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_z_input_0_2/_3, generator/dense/kernel/read)]]\n"
     ]
    }
   ],
   "source": [
    "projection_data_path = '/Users/adalbertoclaudioquiros/Documents/Code/UofG/PhD/GANs'\n",
    "dataset = Dataset(train_images, train_labels, test_images, test_labels, projection_data_path, validation=0.0, shuffle=True)\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "z_dim = 100\n",
    "learning_rate = 1e-4\n",
    "image_type = 'gray'\n",
    "alpha = 0.2\n",
    "\n",
    "# WGAN specific parameters\n",
    "# Gradient clipping value and number of updates in critic per generator.\n",
    "c = 0.1\n",
    "n_critic = 5\n",
    "\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    train(epochs, batch_size, z_dim, learning_rate, dataset, image_type, alpha, n_critic, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
