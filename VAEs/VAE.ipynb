{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<style>.container { width:100% !important; }</style>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "Compressed file ended before the end-of-stream marker was reached",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a62e85098d0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Take train, test images.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;31m# train_images = train.reshape((train.shape[0], 28,28,1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mnist/__init__.py\u001b[0m in \u001b[0;36mtrain_images\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \"\"\"\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdownload_and_parse_mnist_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train-images-idx3-ubyte.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mnist/__init__.py\u001b[0m in \u001b[0;36mdownload_and_parse_mnist_file\u001b[0;34m(fname, target_dir, force)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mfopen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'.gz'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparse_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mnist/__init__.py\u001b[0m in \u001b[0;36mparse_idx\u001b[0;34m(fd)\u001b[0m\n\u001b[1;32m    109\u001b[0m                                     fd.read(4 * num_dimensions))\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyteswap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# looks like array.array reads data as little endian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    480\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m                 raise EOFError(\"Compressed file ended before the \"\n\u001b[0m\u001b[1;32m    483\u001b[0m                                \"end-of-stream marker was reached\")\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Compressed file ended before the end-of-stream marker was reached"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import os\n",
    "import mnist\n",
    "import shutil\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from random import randint\n",
    "\n",
    "# Visualization. \n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Take train, test images.\n",
    "train_images = mnist.train_images()\n",
    "# train_images = train.reshape((train.shape[0], 28,28,1))\n",
    "train_labels = mnist.train_labels()\n",
    "test_images = mnist.test_images()\n",
    "# test_images = test.reshape((test.shape[0], 28,28,1))\n",
    "test_labels = mnist.test_labels()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images: (10000, 28, 28)\n",
      "Train images: (60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simple function to plot number images.\n",
    "def plot_images(plt_num, images, dim):\n",
    "    # Standard parameters for the plot.\n",
    "    \n",
    "    mpl.rcParams[\"figure.figsize\"] = dim, dim\n",
    "    fig = plt.figure()\n",
    "    for i in range(0, plt_num):\n",
    "        fig.add_subplot(1, 10, i+1)\n",
    "        img = images[i,:,:]\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        \n",
    "print('Test images:', test_images.shape)\n",
    "print('Train images:', train_images.shape)\n",
    "plot_images(5, train_images, 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, train_images, train_labels, test_images, test_labels, projection_data_path, validation=0.0, shuffle=False, image_dimensions=28):\n",
    "    \n",
    "        self.train_img = train_images\n",
    "        self.train_labels = train_labels\n",
    "        self.shuffle = shuffle\n",
    "        self.image_dimensions = image_dimensions\n",
    "        self.projection_data_path = projection_data_path\n",
    "        self.metadata_tsv = '%s/metadata.tsv' % projection_data_path\n",
    "        self.sprite = '%s/sprite_train_img.png' % projection_data_path\n",
    "        if self.shuffle:\n",
    "            idx = np.arange(len(self.train_img))\n",
    "            np.random.shuffle(idx)\n",
    "            self.train_img = self.train_img[idx]\n",
    "            self.train_labels = self.train_labels[idx]\n",
    "        \n",
    "        \n",
    "        whole_train = len(train_images)\n",
    "        num_validation_samples = int(whole_train*validation)\n",
    "        num_train_sample = whole_train - num_validation_samples\n",
    "        \n",
    "        \n",
    "        self.train_img = self.train_img[:num_train_sample,:,:]\n",
    "        self.train_img = self.prepare_data(self.train_img)\n",
    "        self.train_labels = self.train_labels[:num_train_sample]\n",
    "        \n",
    "        self.test_img = self.prepare_data(test_images)\n",
    "        self.test_labels = test_labels\n",
    "        \n",
    "        if not validation == 0.0:\n",
    "            self.validation_labels = self.train_labels[num_train_sample+1:]\n",
    "            self.validation_img = self.train_img[num_train_sample+1:,:,:]\n",
    "            self.validation_img = self.prepare_data(self.validation_img)        \n",
    "        \n",
    "    def flatten(self, images):\n",
    "        return images.reshape((images.shape[0], -1))\n",
    "    \n",
    "    def reshape(self, images):\n",
    "        return np.reshape(images, (images.shape[0], self.image_dimensions, self.image_dimensions))\n",
    "    \n",
    "    def normalize(self, images):\n",
    "        # Normalize.\n",
    "        max_value = np.amax(images)\n",
    "        post = images/max_value\n",
    "        return post\n",
    "    \n",
    "    # Function to pre-process the data.\n",
    "    def prepare_data(self, images):\n",
    "        # Reshape data, flattening.\n",
    "        post_images = self.normalize(images)\n",
    "#         post_images = self.flatten(post_images)\n",
    "        return post_images\n",
    "    \n",
    "    def batches(self, batch_size):\n",
    "        n_batches = len(self.train_img)//batch_size\n",
    "        for index in range(0, n_batches, batch_size):\n",
    "            x = self.train_img[index:index+batch_size]\n",
    "            y = self.train_labels[index:index+batch_size]\n",
    "            yield x, y\n",
    "\n",
    "    def random_test(self):\n",
    "        idx = np.arange(len(self.test_img))\n",
    "        np.random.shuffle(idx)\n",
    "        return [self.test_img[idx[0], :, :]]\n",
    "    \n",
    "    def random_train(self):\n",
    "        idx = np.arange(len(self.train_img))\n",
    "        np.random.shuffle(idx)\n",
    "        return [self.train_img[idx[0], :, :]]\n",
    "    \n",
    "    def create_sprite_image(self, images):\n",
    "        \n",
    "        if os.path.isfile(self.sprite):\n",
    "            os.remove(self.sprite)\n",
    "        \n",
    "#         images = 1-images\n",
    "        img_h = images.shape[1]\n",
    "        img_w = images.shape[2]\n",
    "        n_plots = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "\n",
    "        spriteimage = np.ones((img_h * n_plots ,img_w * n_plots ))\n",
    "\n",
    "        for i in range(n_plots):\n",
    "            for j in range(n_plots):\n",
    "                this_filter = i * n_plots + j\n",
    "                if this_filter < images.shape[0]:\n",
    "                    this_img = images[this_filter]\n",
    "                    spriteimage[i * img_h:(i + 1) * img_h, j * img_w:(j + 1) * img_w] = this_img\n",
    "        plt.imsave(self.sprite, spriteimage,cmap='gray')\n",
    "\n",
    "    def create_tsv_file(self, img_labels):\n",
    "        if os.path.isfile(self.metadata_tsv):\n",
    "            os.remove(self.metadata_tsv)\n",
    "        \n",
    "        with open(self.metadata_tsv,'w') as f:\n",
    "            f.write(\"Index\\tLabel\\n\")\n",
    "            for index,label in enumerate(img_labels):\n",
    "                f.write(\"%d\\t%d\\n\" % (index,label))\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Qphi(Z/X) & Decoder Ptheta(X/Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE():\n",
    "    def __init__(self, dim_img, dim_x, dim_z, hidden_dim, learning_rate, batch_size, latent_samples=1, epsilon=1e-6):\n",
    "        \n",
    "        # Parameters.\n",
    "        self.learning_rate = learning_rate\n",
    "        self.latent_samples = latent_samples\n",
    "        self.batch_size = batch_size\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        # Inputs.\n",
    "        self.x_input = tf.placeholder(shape=(None, dim_img, dim_img), dtype=tf.float32, name='imput_image')\n",
    "        self.z_input = tf.placeholder(shape=(None, dim_z), dtype=tf.float32, name='input_latent')\n",
    "        \n",
    "        # Model.\n",
    "        self.weigth_init = tf.contrib.layers.xavier_initializer(uniform=False)\n",
    "        self.vae_loss, self.vae_opt = self.model(self.x_input, self.z_input, dim_img, dim_x, dim_z, hidden_dim, name='model')\n",
    "        \n",
    "        # Tensorboard scalars and images.\n",
    "        tf.summary.scalar('vae_loss', self.vae_loss)\n",
    "        tf.summary.scalar('kl_divergence', self.kl_divergence)\n",
    "        tf.summary.scalar('sampling_expt', self.sampling_expt)\n",
    "        tf.summary.image('Input_Image_X', tf.reshape(self.x_input*255, (-1, dim_img, dim_img, 1)))\n",
    "        tf.summary.image('Reconstruction', tf.cast(tf.reshape(self.p_x_given_z_recon*255, (-1, dim_img, dim_img, 1)), dtype=tf.float32))\n",
    "        tf.summary.histogram(\"Encoder/Mean\", self.mean_z_given_xi)\n",
    "        tf.summary.histogram(\"Encoder/LogSimaSq\", self.logs2_z_given_xi)\n",
    "        tf.summary.histogram(\"Z_sample\", self.z_sample_xi)\n",
    "        tf.summary.histogram(\"Generator/Mean\", self.mean_xi_given_z)\n",
    "        tf.summary.histogram(\"Generator/LogSimaSq\", self.logs2_xi_given_z)\n",
    "        self.merged_summary_op = tf.summary.merge_all()\n",
    "        \n",
    "        # Variable initializer.\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        \n",
    "    def encoder(self, images, dim_z, hidden_dim, reuse, name):\n",
    "        \n",
    "        with tf.variable_scope(name_or_scope=name, reuse=reuse) as scope:\n",
    "            # X Shape (Batch_size, dim_x).\n",
    "            x_flatten = tf.layers.flatten(inputs=images, name='flattening')\n",
    "            \n",
    "            # Hidden Layer (Batch_size, dim_hidden).\n",
    "            hidden_qphi_1 = tf.layers.dense(inputs=x_flatten, units=hidden_dim, activation=tf.nn.relu, kernel_initializer=self.weigth_init, name='hidden_layer_qphi_1')\n",
    "            \n",
    "            # Mean & Sigma, positive numbers softplus on the latter since it cannot be negative. \n",
    "            # Output Shape = (Batch_size, dim_z).\n",
    "            mean_z_given_xi = tf.layers.dense(inputs=hidden_qphi_1, units=dim_z, activation=None, kernel_initializer=self.weigth_init, name='mean_z_given_xi')\n",
    "            logs2_z_given_xi = tf.layers.dense(inputs=hidden_qphi_1, units=dim_z, activation=None, kernel_initializer=self.weigth_init, name='logs2_z_given_xi')\n",
    "        return mean_z_given_xi, logs2_z_given_xi\n",
    "\n",
    "    \n",
    "    def decoder(self, z_sample_given_xi, dim_img, dim_x, hidden_dim, reuse, name):\n",
    "        \n",
    "        with tf.variable_scope(name_or_scope=name, reuse=reuse) as scope:\n",
    "            # Input Layer (Batch_size, dim_z).\n",
    "\n",
    "            # Hidden Layer (Batch_size, dim_hidden).\n",
    "            hidden_ptheta_1 = tf.layers.dense(inputs=z_sample_given_xi, units=hidden_dim, activation=tf.nn.relu, kernel_initializer=self.weigth_init, name='hidden_layer_ptheta_1')\n",
    "            \n",
    "            # Need to introduce tf.contrib.distributions.Independent() to tell tensorflow that the hight and Width dimensions belong to the same data point.  \n",
    "            # For CNN, here we are just reshaping.\n",
    "            mean_xi_given_z = tf.layers.dense(inputs=hidden_ptheta_1, units=dim_x, activation=tf.sigmoid, kernel_initializer=self.weigth_init, name='mean_xi_given_z')\n",
    "            logs2_xi_given_z = tf.layers.dense(inputs=hidden_ptheta_1, units=dim_x, activation=None, kernel_initializer=self.weigth_init, name='logs2_xi_given_z')\n",
    "            mean_xi_given_z = tf.reshape(tensor=mean_xi_given_z, shape=(-1, dim_img, dim_img))\n",
    "            logs2_xi_given_z = tf.reshape(tensor=logs2_xi_given_z, shape=(-1, dim_img, dim_img))\n",
    "            \n",
    "        return mean_xi_given_z, logs2_xi_given_z\n",
    "\n",
    "    \n",
    "    def parametrization_sample(self, mean_z_given_xi, logs2_z_given_xi, dim_z):\n",
    "        sigma_z_given_xi = tf.sqrt(tf.exp(self.logs2_z_given_xi))\n",
    "        \n",
    "        normal = tf.random_normal(shape=tf.shape(mean_z_given_xi), mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "        \n",
    "        return normal*sigma_z_given_xi + mean_z_given_xi\n",
    "        \n",
    "    \n",
    "    def model(self, x_input, z_input, dim_img, dim_x, dim_z, hidden_dim, name):\n",
    "        with tf.variable_scope(name) as scope:\n",
    "            '''\n",
    "            ENCODER.\n",
    "            Mean and Sigma from datapoint Xi. Shape = (Batch_size, dim_z).\n",
    "            In the encoder, the neural network is able to approximate fairly well the s.t.d. for the latent space of the given sample Xi.\n",
    "            '''\n",
    "            self.mean_z_given_xi, self.logs2_z_given_xi = self.encoder(x_input, dim_z, hidden_dim, reuse=False, name='Qphi_z_given_x')\n",
    "            \n",
    "            '''\n",
    "            PARAMETRIZATION TRICK.\n",
    "            Building Normal distribution and pushes mean, scale s.t.d.\n",
    "            Makes sure that Tensorflow takes into account that mean and sigma are parameter so it propagates gradients. \n",
    "            Get sample Z from the conditional distribution given Xi.\n",
    "            Each dim z r.v is independent from each other, we assume that the covariance between them is 0.\n",
    "            \n",
    "            Trying two different way here:\n",
    "                A. 1st way, create normal and parameterized it. Sample.\n",
    "                B. 2nd way, sample from normal and scale.\n",
    "            \n",
    "            '''\n",
    "#             q_z_given_x = tfp.distributions.MultivariateNormalDiag(loc=self.mean_z_given_xi, scale_diag=self.sigma_z_g_xi)\n",
    "#             assert q_z_given_x.reparameterization_type == tfp.distributions.FULLY_REPARAMETERIZED\n",
    "#             self.z_sample_xi = q_z_given_x.sample()\n",
    "\n",
    "            self.z_sample_xi = self.parametrization_sample(self.mean_z_given_xi, self.logs2_z_given_xi, dim_z)\n",
    "            \n",
    "            '''\n",
    "            P(Z)\n",
    "            Modeling P(z) as a Normal distribution.\n",
    "            Shape = (Batch_size, dim_z).\n",
    "            Not needed if you go for the 2nd.\n",
    "            '''\n",
    "#             location = tf.zeros_like(self.mean_z_given_xi)\n",
    "#             scale = tf.ones_like(self.sigma_z_g_xi)\n",
    "#             self.p_z = tfp.distributions.MultivariateNormalDiag(loc=location, scale_diag=scale)\n",
    "            \n",
    "            '''\n",
    "            DECODER.\n",
    "            Shape = (Batch_size, dim_x).\n",
    "            '''\n",
    "            self.mean_xi_given_z, self.logs2_xi_given_z = self.decoder(self.z_sample_xi, dim_img, dim_x, hidden_dim, reuse=False, name='Ptheta_x_given_x')\n",
    "            self.p_x_given_z_recon = self.mean_xi_given_z\n",
    "            \n",
    "            '''\n",
    "            DISTRIBUTIONS FOR ENCODER.\n",
    "            \n",
    "            1. Gaussian.\n",
    "                - Important Note: If we use the NN to approximate the s.t.d. the error in approximation will introduce noise and scale it when you doing the log_prob,\n",
    "                since this s.t.d. will go into a log, with a lower value than one scaling the approximation problem.\n",
    "                The solution to this is to introduce directly the approximation error with log(sigma**2).\n",
    "                - Furhter insight into this, not only the neural network is introducing the error int the approximation, since me approximate with the sample on the \n",
    "                latent space, this is also introduces an error than is later magnified by the NN and the log function.\n",
    "                - Besides, it needs the epsilon (1e-6) to be stable, otherwise Encoder mean will finish being NaN.\n",
    "                p_x_given_z = tfp.distributions.Independent(tfp.distributions.MultivariateNormalDiag(loc=self.mean_xi_given_z, scale_diag=self.sigma_xi_given_z))\n",
    "                assert p_x_given_z.reparameterization_type == tfp.distributions.FULLY_REPARAMETERIZED\n",
    "                \n",
    "            2. Bernoulli\n",
    "                p_x_given_z = tfp.distributions.Independent(tfp.distributions.Bernoulli(logits=self.mean_xi_given_z), reinterpreted_batch_ndims=2).\n",
    "                self.p_x_given_z_recon = p_x_given_z.sample().\n",
    "            '''\n",
    "            \n",
    "            '''\n",
    "            ELBO and Loss.\n",
    "            ELBO: Building lower bound, the intent is to maximize this so the log(P(Xi)) maximizes.\n",
    "            Two ways of implementing this according to the parametrization trick: \n",
    "                - Careful here with the balance on the reduce_sum/mean.\n",
    "                - KL Divergence: Q(Z/X) and P(Z).\n",
    "                    1. Use KL divergence form TensorFlow Probability Library:\n",
    "                        self.kl_divergence = tf.reduce_sum(tfp.distributions.kl_divergence(distribution_a=q_z_given_x, distribution_b=self.p_z), axis=-1)\n",
    "                    2. Compute KL divergence analytically.\n",
    "                - Reconstruction error from sampled enconding:\n",
    "                    1. Use log_prob from TensorFlow Probability Library.\n",
    "                    2. Compute analytically for pdf:\n",
    "                        2.a Gaussian.\n",
    "                        2.b Bernoulli: self.sampling_expt = tf.reduce_sum(p_x_given_z.log_prob(self.x_input), axis=-1)\n",
    "            Loss: We try to maximize the lower bound, so our objective is to minimize our loss.\n",
    "            '''\n",
    "            \n",
    "            # KL Divergence.\n",
    "            z_sigma_2 = tf.exp(self.logs2_z_given_xi)\n",
    "            z_log_sigma_2 = tf.log(z_sigma_2 + self.epsilon)\n",
    "            mean_z_2 = tf.square(self.mean_z_given_xi)\n",
    "            self.kl_divergence= -.5*tf.reduce_sum(1 + z_log_sigma_2 -mean_z_2 -z_sigma_2, axis=-1)\n",
    "            self.kl_divergence = tf.reduce_mean(-self.kl_divergence, axis=-1)\n",
    "            \n",
    "            # Recon error from encoding space of datapoint.\n",
    "            x_sigma_2 = tf.exp(self.logs2_xi_given_z)\n",
    "            exp_ls2 = tf.square(self.x_input - self.mean_xi_given_z)/(self.epsilon + x_sigma_2)\n",
    "            se = tf.log(2*np.pi) + tf.log(self.epsilon + x_sigma_2) + exp_ls2\n",
    "            self.sampling_expt = tf.reduce_sum(-.5*se, axis=[1,2])\n",
    "            self.sampling_expt = tf.reduce_mean(self.sampling_expt, axis=-1)\n",
    "\n",
    "            elbo = self.kl_divergence + self.sampling_expt\n",
    "            vae_loss = -elbo\n",
    "            vae_opt = tf.train.AdamOptimizer(self.learning_rate).minimize(vae_loss)\n",
    "            \n",
    "            '''\n",
    "            Generator to sample.\n",
    "            Shape = (Batch_size, dim_x).\n",
    "            '''\n",
    "            self.generated_mean, self.generated_logs2 = self.decoder(self.z_input, dim_img, dim_x, hidden_dim, reuse=True, name='Ptheta_x_given_x')\n",
    "        \n",
    "        return vae_loss, vae_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary function to plot generated digits.\n",
    "def plot_samples(vae, sess, lat_img_run, e):\n",
    "    \n",
    "    # Normal distribution to generate images.\n",
    "    location = tf.zeros((1, dim_z))\n",
    "    scale = tf.ones((1, dim_z))\n",
    "    normal = tfp.distributions.MultivariateNormalDiag(loc=location, scale_diag=scale)\n",
    "    z_input = np.array(normal.sample(36).eval())\n",
    "    z_input = z_input[:, 0, :]\n",
    "    \n",
    "    generated = sess.run(vae.generated_mean, feed_dict={vae.z_input: z_input})\n",
    "    \n",
    "    n_sqrt = int(np.sqrt(generated.shape[0]))\n",
    "    fig, axes = plt.subplots(n_sqrt, n_sqrt, sharex=True, sharey=True, figsize=(n_sqrt*3, n_sqrt*3))\n",
    "    for ii, ax in zip(range(0, generated.shape[0]), axes.flatten()):\n",
    "        ax.imshow(generated[ii, :, :]*255, aspect='equal', cmap='gray')\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)    \n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.savefig( '%s/%s.png' % (lat_img_run, e))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters:  608868\n",
      "model:\n",
      "\tQphi_z_given_x:\n",
      "\t\thidden_layer_qphi_1:\n",
      "\t\t\tkernel:0 - shape: (784, 250) param: 196000 \n",
      "\t\t\tbias:0 - shape: (250,) param: 250 \n",
      "\t\tmean_z_given_xi:\n",
      "\t\t\tkernel:0 - shape: (250, 25) param: 6250 \n",
      "\t\t\tbias:0 - shape: (25,) param: 25 \n",
      "\t\tlogs2_z_given_xi:\n",
      "\t\t\tkernel:0 - shape: (250, 25) param: 6250 \n",
      "\t\t\tbias:0 - shape: (25,) param: 25 \n",
      "\tPtheta_x_given_x:\n",
      "\t\thidden_layer_ptheta_1:\n",
      "\t\t\tkernel:0 - shape: (25, 250) param: 6250 \n",
      "\t\t\tbias:0 - shape: (250,) param: 250 \n",
      "\t\tmean_xi_given_z:\n",
      "\t\t\tkernel:0 - shape: (250, 784) param: 196000 \n",
      "\t\t\tbias:0 - shape: (784,) param: 784 \n",
      "\t\tlogs2_xi_given_z:\n",
      "\t\t\tkernel:0 - shape: (250, 784) param: 196000 \n",
      "\t\t\tbias:0 - shape: (784,) param: 784 \n"
     ]
    }
   ],
   "source": [
    "show_every = 1000\n",
    "show_latent = 250\n",
    "\n",
    "distribut = 'Init_Gaussian'\n",
    "layers = 2\n",
    "\n",
    "# GPU Options\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Model options.\n",
    "batch_size = 20\n",
    "dim_img = 28\n",
    "dim_x = dim_img**2\n",
    "dim_z = 25\n",
    "hidden_dim = 250\n",
    "lr = 1e-4\n",
    "epochs = int(5e3)\n",
    "\n",
    "# Directories.\n",
    "run_name = '%s-%s-layer-full-bs_%s_dimz_%s_dimh_%s_lr_%s' % (distribut, layers, batch_size, dim_z, hidden_dim, lr)\n",
    "projection_data_path = '/Users/adalbertoclaudioquiros/Documents/Code/UofG/PhD/MnistVAE/VAE/'\n",
    "tensorboard_path = '/Users/adalbertoclaudioquiros/Documents/Code/UofG/PhD/MnistVAE/VAE/tensorboard'\n",
    "latent_images = '/Users/adalbertoclaudioquiros/Documents/Code/UofG/PhD/MnistVAE/VAE/latent_images'\n",
    "tb_session = '%s/%s' % (tensorboard_path, run_name)\n",
    "lat_img_run = '%s/%s' % (latent_images, run_name)\n",
    "if os.path.isdir(tb_session):\n",
    "    shutil.rmtree(tb_session)\n",
    "if os.path.isdir(lat_img_run):\n",
    "    shutil.rmtree(lat_img_run)\n",
    "os.makedirs(tb_session)\n",
    "os.makedirs(lat_img_run)\n",
    "\n",
    "# Tensor tracking.\n",
    "run_metadata = tf.RunMetadata()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "vae = VAE(dim_img=dim_img, dim_x=dim_x, dim_z=dim_z, hidden_dim=hidden_dim, learning_rate=lr, batch_size=batch_size)\n",
    "data = Dataset(train_images, train_labels, test_images, test_labels, projection_data_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed to create CUPTI subcriber.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed to create CUPTI subcriber.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-fd963df828c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;31m# Train and store data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvae_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0msummary_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvae_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvae_mean_z_g_xi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerged_summary_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvae_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_z_given_xi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunOptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFULL_TRACE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_partition_graphs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed to create CUPTI subcriber."
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "iteration = 0\n",
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "    summary_writer = tf.summary.FileWriter(tb_session, graph_def=sess.graph_def)\n",
    "    sess.run(vae.init)\n",
    "    for e in range(epochs+1):\n",
    "        for images, labels in data.batches(batch_size):\n",
    "        \n",
    "            # maximum across all sessions and .run calls so far\n",
    "#             a = sess.run(tf.contrib.memory_stats.MaxBytesInUse())\n",
    "#             print(a)\n",
    "            # current usage\n",
    "#             b = sess.run(tf.contrib.memory_stats.BytesInUse())\n",
    "#             print(b)\n",
    "            \n",
    "            # Train and store data \n",
    "            sess.run(vae.vae_opt, feed_dict={vae.x_input: images})\n",
    "            summary_str, vae_loss, vae_mean_z_g_xi = sess.run([vae.merged_summary_op, vae.vae_loss, vae.mean_z_given_xi], feed_dict={vae.x_input: images}, options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE, output_partition_graphs=True), run_metadata=run_metadata)\n",
    "            summary_writer.add_summary(summary_str, iteration)\n",
    "\n",
    "            with open(\"%s/run2.txt\" % os.getcwd(), \"w\") as out:\n",
    "                out.write(str(run_metadata))\n",
    "            \n",
    "            if iteration%show_every==0:\n",
    "                \n",
    "                # Run batch and print loss.\n",
    "                print('Epoch %s/%s... VAE Loss: %s' % (str(e), str(epochs), str(vae_loss)))\n",
    "            iteration += 1\n",
    "\n",
    "        if e%show_latent == 0:\n",
    "            summary_str, mean_z_g_xi = sess.run([vae.merged_summary_op, vae.mean_z_given_xi], feed_dict={vae.x_input: data.test_img})\n",
    "            summary_writer.add_summary(summary_str, iteration)\n",
    "            plot_samples(vae, sess, lat_img_run, e)\n",
    "\n",
    "    data.create_sprite_image(data.test_img[:2500])\n",
    "    data.create_tsv_file(data.test_labels[:2500])\n",
    "    mean_z_g_xi = sess.run(vae.mean_z_given_xi, feed_dict={vae.x_input: data.test_img[:2500]})\n",
    "    latent = tf.Variable(mean_z_g_xi, name='Latent_Space_Z_%s' % e)\n",
    "\n",
    "    saver = tf.train.Saver([latent])\n",
    "    sess.run(latent.initializer)\n",
    "    saver.save(sess, os.path.join(tb_session, 'latent_%s.ckpt' % e))\n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = latent.name\n",
    "    embedding.sprite.image_path = data.sprite\n",
    "    embedding.sprite.single_image_dim.extend([28,28])\n",
    "    embedding.metadata_path = data.metadata_tsv\n",
    "\n",
    "    projector.visualize_embeddings(summary_writer, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1.0,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1.0,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16.0,
    "lenType": 16.0,
    "lenVar": 40.0
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "689.219px",
    "left": "844.848px",
    "right": "20px",
    "top": "115.945px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
