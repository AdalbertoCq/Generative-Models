{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "NotFoundError",
     "evalue": "dlopen(/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/nccl/python/ops/_nccl_ops.so, 6): Symbol not found: _ncclAllReduce\n  Referenced from: /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/nccl/python/ops/_nccl_ops.so\n  Expected in: flat namespace\n in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/nccl/python/ops/_nccl_ops.so",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bae8ad0d3213>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Visualization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprojector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/distribute/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# pylint: disable=unused-import,wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_tower_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmirrored_strategy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMirroredStrategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMonitor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_tower_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvalue_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/cross_tower_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpycoll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnccl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/nccl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnccl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnccl_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mall_max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnccl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnccl_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mall_min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnccl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnccl_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mall_prod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/nccl/python/ops/nccl_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m _nccl_ops_so = loader.load_op_library(\n\u001b[0;32m---> 30\u001b[0;31m     resource_loader.get_path_to_datafile('_nccl_ops.so'))\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/util/loader.py\u001b[0m in \u001b[0;36mload_op_library\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresource_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path_to_datafile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_library\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_op_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Could not load %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/load_library.py\u001b[0m in \u001b[0;36mload_op_library\u001b[0;34m(library_filename)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0munable\u001b[0m \u001b[0mto\u001b[0m \u001b[0mload\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlibrary\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mget\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpython\u001b[0m \u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \"\"\"\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mlib_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_LoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibrary_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0mop_list_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetOpList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: dlopen(/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/nccl/python/ops/_nccl_ops.so, 6): Symbol not found: _ncclAllReduce\n  Referenced from: /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/nccl/python/ops/_nccl_ops.so\n  Expected in: flat namespace\n in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/nccl/python/ops/_nccl_ops.so"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import os\n",
    "import mnist\n",
    "import shutil\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import tensorflow_probability as tfp\n",
    "from random import randint\n",
    "\n",
    "# Visualization. \n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Take train, test images.\n",
    "train_images = mnist.train_images()\n",
    "# train_images = train.reshape((train.shape[0], 28,28,1))\n",
    "train_labels = mnist.train_labels()\n",
    "test_images = mnist.test_images()\n",
    "# test_images = test.reshape((test.shape[0], 28,28,1))\n",
    "test_labels = mnist.test_labels()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images: (10000, 28, 28)\n",
      "Train images: (60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simple function to plot number images.\n",
    "def plot_images(plt_num, images, dim):\n",
    "    # Standard parameters for the plot.\n",
    "    \n",
    "    mpl.rcParams[\"figure.figsize\"] = dim, dim\n",
    "    fig = plt.figure()\n",
    "    for i in range(0, plt_num):\n",
    "        fig.add_subplot(1, 10, i+1)\n",
    "        img = images[i,:,:]\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        \n",
    "print('Test images:', test_images.shape)\n",
    "print('Train images:', train_images.shape)\n",
    "plot_images(5, train_images, 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, train_images, train_labels, test_images, test_labels, projection_data_path, validation=0.0, shuffle=False, image_dimensions=28):\n",
    "    \n",
    "        self.train_img = train_images\n",
    "        self.train_labels = train_labels\n",
    "        self.shuffle = shuffle\n",
    "        self.image_dimensions = image_dimensions\n",
    "        self.projection_data_path = projection_data_path\n",
    "        self.metadata_tsv = '%s/metadata.tsv' % projection_data_path\n",
    "        self.sprite = '%s/sprite_train_img.png' % projection_data_path\n",
    "        if self.shuffle:\n",
    "            idx = np.arange(len(self.train_img))\n",
    "            np.random.shuffle(idx)\n",
    "            self.train_img = self.train_img[idx]\n",
    "            self.train_labels = self.train_labels[idx]\n",
    "        \n",
    "        \n",
    "        whole_train = len(train_images)\n",
    "        num_validation_samples = int(whole_train*validation)\n",
    "        num_train_sample = whole_train - num_validation_samples\n",
    "        \n",
    "        \n",
    "        self.train_img = self.train_img[:num_train_sample,:,:]\n",
    "        self.train_img = self.prepare_data(self.train_img)\n",
    "        self.train_labels = self.train_labels[:num_train_sample]\n",
    "        \n",
    "        self.test_img = self.prepare_data(test_images)\n",
    "        self.test_labels = test_labels\n",
    "        \n",
    "        if not validation == 0.0:\n",
    "            self.validation_labels = self.train_labels[num_train_sample+1:]\n",
    "            self.validation_img = self.train_img[num_train_sample+1:,:,:]\n",
    "            self.validation_img = self.prepare_data(self.validation_img)        \n",
    "        \n",
    "    def flatten(self, images):\n",
    "        return images.reshape((images.shape[0], -1))\n",
    "    \n",
    "    def reshape(self, images):\n",
    "        return np.reshape(images, (images.shape[0], self.image_dimensions, self.image_dimensions))\n",
    "    \n",
    "    def normalize(self, images):\n",
    "        # Normalize.\n",
    "        max_value = np.amax(images)\n",
    "        post = images/max_value\n",
    "        return post\n",
    "    \n",
    "    # Function to pre-process the data.\n",
    "    def prepare_data(self, images):\n",
    "        # Reshape data, flattening.\n",
    "        post_images = self.normalize(images)\n",
    "#         post_images = self.flatten(post_images)\n",
    "        return post_images\n",
    "    \n",
    "    def batches(self, batch_size):\n",
    "        n_batches = len(self.train_img)//batch_size\n",
    "        for index in range(0, n_batches, batch_size):\n",
    "            x = self.train_img[index:index+batch_size]\n",
    "            y = self.train_labels[index:index+batch_size]\n",
    "            yield x, y\n",
    "\n",
    "    def random_test(self):\n",
    "        idx = np.arange(len(self.test_img))\n",
    "        np.random.shuffle(idx)\n",
    "        return [self.test_img[idx[0], :, :]]\n",
    "    \n",
    "    def random_train(self):\n",
    "        idx = np.arange(len(self.train_img))\n",
    "        np.random.shuffle(idx)\n",
    "        return [self.train_img[idx[0], :, :]]\n",
    "    \n",
    "    def create_sprite_image(self, images):\n",
    "        \n",
    "        if os.path.isfile(self.sprite):\n",
    "            os.remove(self.sprite)\n",
    "        \n",
    "#         images = 1-images\n",
    "        img_h = images.shape[1]\n",
    "        img_w = images.shape[2]\n",
    "        n_plots = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "\n",
    "        spriteimage = np.ones((img_h * n_plots ,img_w * n_plots ))\n",
    "\n",
    "        for i in range(n_plots):\n",
    "            for j in range(n_plots):\n",
    "                this_filter = i * n_plots + j\n",
    "                if this_filter < images.shape[0]:\n",
    "                    this_img = images[this_filter]\n",
    "                    spriteimage[i * img_h:(i + 1) * img_h, j * img_w:(j + 1) * img_w] = this_img\n",
    "        plt.imsave(self.sprite, spriteimage,cmap='gray')\n",
    "\n",
    "    def create_tsv_file(self, img_labels):\n",
    "        if os.path.isfile(self.metadata_tsv):\n",
    "            os.remove(self.metadata_tsv)\n",
    "        \n",
    "        with open(self.metadata_tsv,'w') as f:\n",
    "            f.write(\"Index\\tLabel\\n\")\n",
    "            for index,label in enumerate(img_labels):\n",
    "                f.write(\"%d\\t%d\\n\" % (index,label))\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Qphi(Z/X) & Decoder Ptheta(X/Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE():\n",
    "    def __init__(self, dim_img, dim_x, dim_z, hidden_dim, learning_rate, latent_samples=1):\n",
    "        \n",
    "        # Shape=(Batch_size, dim_x).\n",
    "        self.learning_rate = learning_rate\n",
    "        self.latent_samples = latent_samples\n",
    "        self.x_input = tf.placeholder(shape=(None, dim_img, dim_img), dtype=tf.float32, name='input_image')\n",
    "        self.y_input = tf.placeholder(shape=(None, 1), dtype=tf.float32, name='input_label')\n",
    "        self.y_gen = tf.placeholder(shape=(None, 1), dtype=tf.float32, name='input_label_gen')\n",
    "        self.z_input = tf.placeholder(shape=(None, dim_z), dtype=tf.float32, name='input_latent')\n",
    "        self.vae_loss, self.vae_opt = self.model(self.x_input, self.z_input, self.y_input, self.y_gen, dim_img, dim_x, dim_z, hidden_dim, name='model')\n",
    "        \n",
    "        # Tensorboard scalars and images.\n",
    "        tf.summary.scalar('vae_loss', self.vae_loss)\n",
    "        tf.summary.scalar('kl_divergence', self.kl_divergence)\n",
    "        tf.summary.scalar('sampling_expt', self.sampling_expt)\n",
    "        tf.summary.image('Input_Image_X', tf.reshape(self.x_input*255, (-1, dim_img, dim_img, 1)))\n",
    "        tf.summary.image('Reconstruction', tf.cast(tf.reshape(self.p_x_given_z_recon*255, (-1, dim_img, dim_img, 1)), dtype=tf.float32))\n",
    "        tf.summary.histogram(\"Encoder/Mean\", self.mean_z_g_xi)\n",
    "        tf.summary.histogram(\"Encoder/Sigma\", self.sigma_z_g_xi)\n",
    "        tf.summary.histogram(\"Z_sample\", self.z_sample_xi)\n",
    "        tf.summary.histogram(\"Generator/Mean\", self.mean_x_g_zi)\n",
    "        tf.summary.histogram(\"Generator/LogSigmaSquare\", self.logs2_xi_given_z)\n",
    "        \n",
    "        self.merged_summary_op = tf.summary.merge_all()\n",
    "        \n",
    "        # Variable initializer.\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        \n",
    "    def encoder(self, images, labels, dim_z, hidden_dim, reuse, name):\n",
    "        \n",
    "        with tf.variable_scope(name_or_scope=name, reuse=reuse) as scope:\n",
    "            # X Shape (Batch_size, dim_x).\n",
    "            x_flatten = tf.layers.flatten(inputs=images, name='flattening')\n",
    "            input_concat = tf.concat([x_flatten, labels], axis=-1)\n",
    "            \n",
    "            # Hidden Layer (Batch_size, dim_hidden).\n",
    "            hidden_qphi_1 = tf.layers.dense(inputs=input_concat, units=hidden_dim, activation=tf.nn.relu, name='hidden_layer_qphi_1')\n",
    "            \n",
    "            # Mean & Sigma, positive numbers softplus on the latter since it cannot be negative. \n",
    "            # Output Shape = (Batch_size, dim_z).\n",
    "            mean_z_given_xi = tf.layers.dense(inputs=hidden_qphi_1, units=dim_z, activation=None, name='mean_z_given_xi')\n",
    "            sigma_z_given_xi = tf.layers.dense(inputs=hidden_qphi_1, units=dim_z, activation=tf.nn.softplus, name='sigma_z_given_xi')\n",
    "        return mean_z_given_xi, sigma_z_given_xi\n",
    "\n",
    "    \n",
    "    def decoder(self, z_sample_given_xi, labels, dim_img, dim_x, hidden_dim, reuse, name):\n",
    "        \n",
    "        with tf.variable_scope(name_or_scope=name, reuse=reuse) as scope:\n",
    "            # Input Layer (Batch_size, dim_z).\n",
    "            input_concat = tf.concat([z_sample_given_xi, labels], axis=-1)\n",
    "            \n",
    "            # Hidden Layer (Batch_size, dim_hidden).\n",
    "            hidden_ptheta_1 = tf.layers.dense(inputs=input_concat, units=hidden_dim, activation=tf.nn.relu, name='hidden_layer_ptheta_1')\n",
    "            \n",
    "            # Need to introduce tf.contrib.distributions.Independent() to tell tensorflow that the hight and Width dimensions belong to the same data point.  \n",
    "            # For CNN, here we are just reshaping.\n",
    "            mean_xi_given_z = tf.layers.dense(inputs=hidden_ptheta_1, units=dim_x, activation=tf.nn.sigmoid, name='mean_xi_given_z')\n",
    "            logs2_xi_given_z = tf.layers.dense(inputs=mean_xi_given_z, units=dim_x, activation=tf.nn.softplus, name='logs2_xi_given_z')\n",
    "            mean_xi_given_z = tf.reshape(tensor=mean_xi_given_z, shape=(-1, dim_img, dim_img))\n",
    "            logs2_xi_given_z = tf.reshape(tensor=logs2_xi_given_z, shape=(-1, dim_img, dim_img))\n",
    "            \n",
    "        return mean_xi_given_z, logs2_xi_given_z\n",
    "\n",
    "    \n",
    "    def model(self, x_input, z_input, y_input, y_gen, dim_img, dim_x, dim_z, hidden_dim, name):\n",
    "        with tf.variable_scope(name) as scope:\n",
    "            \n",
    "            ## ENCODER.\n",
    "            # Mean and Sigma from datapoint Xi. Shape = (Batch_size, dim_z).\n",
    "            # In the encoder, the neural network is able to approximate fairly well the s.t.d. for the latent space of the given sample Xi.\n",
    "            self.mean_z_g_xi, self.sigma_z_g_xi = self.encoder(x_input, y_input, dim_z, hidden_dim, reuse=False, name='Qphi_z_given_x')\n",
    "            \n",
    "            # PARAMETRIZATION TRICK.\n",
    "            # Building Normal distribution and pushes mean, scale s.t.d.\n",
    "            # Makes sure that Tensorflow takes into account that mean and sigma are parameter so it propagates gradients. \n",
    "            q_z_given_x = tfp.distributions.MultivariateNormalDiag(loc=self.mean_z_g_xi, scale_diag=self.sigma_z_g_xi)\n",
    "            assert q_z_given_x.reparameterization_type == tfp.distributions.FULLY_REPARAMETERIZED\n",
    "            # Get sample Z from the conditional distribution given Xi.\n",
    "            # Shape = (Batch_size, dim_z).\n",
    "            # Each dim z r.v is independent from each other, we assume that the covariance between them is 0.\n",
    "            self.z_sample_xi = q_z_given_x.sample()\n",
    "            \n",
    "            \n",
    "            # Modeling P(z) as a Normal distribution.\n",
    "            # Shape = (Batch_size, dim_z).\n",
    "            location = tf.zeros_like(self.mean_z_g_xi)\n",
    "            scale = tf.ones_like(self.sigma_z_g_xi)\n",
    "            self.p_z = tfp.distributions.MultivariateNormalDiag(loc=location, scale_diag=scale)\n",
    "            \n",
    "            \n",
    "            # DECODER.\n",
    "            # Shape = (Batch_size, dim_x).\n",
    "            self.mean_x_g_zi, self.logs2_xi_given_z = self.decoder(self.z_sample_xi, y_input, dim_img, dim_x, hidden_dim, reuse=False, name='Ptheta_x_given_x')\n",
    "            self.p_x_given_z_recon = self.mean_x_g_zi\n",
    "            \n",
    "            # DISTRIBUTIONS FOR ENCODER.\n",
    "            # 1. Gassian.\n",
    "            # Important Note: If we use the NN to approximate the s.t.d. the error in approximation will introduce noise and scale it when you doing the log_prob,\n",
    "            # since this s.t.d. will go into a log, with a lower value than one scaling the approximation problem.\n",
    "            # The solution to this is to introduce directly the approximation error with log(sigma**2).\n",
    "            # Furhter insight into this, not only the neural network is introducing the error int the approximation, since me approximate with the sample on the \n",
    "            # latent space, this is also introduces an error than is later magnified by the NN and the log function.\n",
    "#             p_x_given_z = tfp.distributions.Independent(tfp.distributions.MultivariateNormalDiag(loc=self.mean_x_g_zi, scale_diag=self.sigma_xi_given_z))\n",
    "#             assert p_x_given_z.reparameterization_type == tfp.distributions.FULLY_REPARAMETERIZED\n",
    "            \n",
    "            # 2. Bernoulli\n",
    "#             p_x_given_z = tfp.distributions.Independent(tfp.distributions.Bernoulli(logits=self.mean_x_g_zi), reinterpreted_batch_ndims=2).\n",
    "#             self.p_x_given_z_recon = p_x_given_z.sample().\n",
    "        \n",
    "            \n",
    "            # ELBO: Building lower bound, the intent is to maximize this so the log(P(Xi)) maximizes.\n",
    "            # 1st Term: KL Divergence: Q(Z/X) and P(Z).\n",
    "            # Careful here with the balance on the reduce_sum/mean.\n",
    "            self.kl_divergence = tf.reduce_sum(tfp.distributions.kl_divergence(distribution_a=q_z_given_x, distribution_b=self.p_z), axis=-1)\n",
    "#             kl= -tf.reduce_sum(.5*(1 + self.logs2_z_given_xi - (self.mean_z_g_xi**2) - tf.exp(self.logs2_z_given_xi)), axis=-1)\n",
    "#             self.kl_divergence = tf.reduce_sum(kl, axis=-1)\n",
    "            \n",
    "            # 2nd Term: Expectation error of the decoder form the encoder. \n",
    "            # With Bernoulli has decoder, we can use prob_lob, usign the Gaussian forces to use the analytical to avoid the error scaling from log and s.t.d.\n",
    "            \n",
    "            # 2.A. Gaussian:\n",
    "            exp_ls2 = ((self.x_input - self.mean_x_g_zi)**2)/tf.exp(self.logs2_xi_given_z)\n",
    "            se = tf.log(2*np.pi) + self.logs2_xi_given_z + exp_ls2\n",
    "            se = tf.reduce_sum(-.5*se, axis=[1,2])\n",
    "            self.sampling_expt = tf.reduce_sum(se, axis=-1)\n",
    "\n",
    "            # 2.B. Berboulli:\n",
    "#             self.sampling_expt = tf.reduce_sum(p_x_given_z.log_prob(self.x_input), axis=-1)\n",
    "\n",
    "            # We try to maximize the lower bound, so our objective is to minimize our loss.\n",
    "            elbo = -self.kl_divergence + self.sampling_expt\n",
    "            vae_loss = -elbo\n",
    "            vae_opt = tf.train.AdamOptimizer(self.learning_rate).minimize(vae_loss)\n",
    "            \n",
    "            # Generator to sample.\n",
    "            # Shape = (Batch_size, dim_x).\n",
    "            self.generated_mean, self.generated_logs2 = self.decoder(z_input, y_gen, dim_img, dim_x, hidden_dim, reuse=True, name='Ptheta_x_given_x')\n",
    "        \n",
    "        return vae_loss, vae_opt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary function to plot generated digits.\n",
    "def plot_samples(vae, sess, lat_img_run, e):\n",
    "    images = 36\n",
    "    \n",
    "    # Normal distribution to generate images.\n",
    "    location = tf.zeros((1, dim_z))\n",
    "    scale = tf.ones((1, dim_z))\n",
    "    normal = tfp.distributions.MultivariateNormalDiag(loc=location, scale_diag=scale)\n",
    "    z_input = np.array(normal.sample(images).eval())\n",
    "    z_input = z_input[:, 0, :]\n",
    "    labels = np.array([randint(0, 9) for i in range(images)]).reshape((-1,1))\n",
    "    \n",
    "    generated = sess.run(vae.generated_mean, feed_dict={vae.z_input: z_input, vae.y_gen: labels})\n",
    "    \n",
    "    n_sqrt = int(np.sqrt(generated.shape[0]))\n",
    "    fig, axes = plt.subplots(n_sqrt, n_sqrt, sharex=True, sharey=True, figsize=(n_sqrt*3, n_sqrt*3))\n",
    "    for ii, ax in zip(range(0, generated.shape[0]), axes.flatten()):\n",
    "        ax.imshow(generated[ii, :, :]*255, aspect='equal', cmap='gray')\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)    \n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.savefig( '%s/%s.png' % (lat_img_run, e))\n",
    "    plt.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "run_control": {
     "marked": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n",
      "Epoch 0/10000... VAE Loss: 63256.54\n",
      "Epoch 66/10000... VAE Loss: 47280.92\n",
      "Epoch 133/10000... VAE Loss: 47140.844\n",
      "Epoch 200/10000... VAE Loss: 47145.195\n",
      "Epoch 266/10000... VAE Loss: 47173.266\n",
      "Epoch 333/10000... VAE Loss: 47065.523\n",
      "Epoch 400/10000... VAE Loss: 47093.71\n",
      "Epoch 466/10000... VAE Loss: 47082.996\n",
      "Epoch 533/10000... VAE Loss: 47053.66\n",
      "Epoch 600/10000... VAE Loss: 47089.25\n",
      "Epoch 666/10000... VAE Loss: 47042.29\n",
      "Epoch 733/10000... VAE Loss: 46986.387\n",
      "Epoch 800/10000... VAE Loss: 47048.375\n",
      "Epoch 866/10000... VAE Loss: 47029.12\n",
      "Epoch 933/10000... VAE Loss: 46995.6\n",
      "Epoch 1000/10000... VAE Loss: 46984.547\n",
      "Epoch 1066/10000... VAE Loss: 46986.883\n",
      "Epoch 1133/10000... VAE Loss: 46960.387\n",
      "Epoch 1200/10000... VAE Loss: 47018.41\n",
      "Epoch 1266/10000... VAE Loss: 46993.69\n",
      "Epoch 1333/10000... VAE Loss: 46960.434\n",
      "Epoch 1400/10000... VAE Loss: 46992.664\n",
      "Epoch 1466/10000... VAE Loss: 46973.71\n",
      "Epoch 1533/10000... VAE Loss: 46974.87\n",
      "Epoch 1600/10000... VAE Loss: 46992.297\n",
      "Epoch 1666/10000... VAE Loss: 46933.53\n",
      "Epoch 1733/10000... VAE Loss: 46939.98\n",
      "Epoch 1800/10000... VAE Loss: 46955.81\n",
      "Epoch 1866/10000... VAE Loss: 46958.973\n",
      "Epoch 1933/10000... VAE Loss: 46945.0\n",
      "Epoch 2000/10000... VAE Loss: 46983.668\n",
      "Epoch 2066/10000... VAE Loss: 46928.03\n",
      "Epoch 2133/10000... VAE Loss: 46906.844\n",
      "Epoch 2200/10000... VAE Loss: 46941.945\n",
      "Epoch 2266/10000... VAE Loss: 46923.51\n",
      "Epoch 2333/10000... VAE Loss: 46943.543\n",
      "Epoch 2400/10000... VAE Loss: 46918.89\n",
      "Epoch 2466/10000... VAE Loss: 46925.3\n",
      "Epoch 2533/10000... VAE Loss: 46892.586\n",
      "Epoch 2600/10000... VAE Loss: 46945.016\n",
      "Epoch 2666/10000... VAE Loss: 46904.098\n",
      "Epoch 2733/10000... VAE Loss: 46908.58\n",
      "Epoch 2800/10000... VAE Loss: 46961.723\n",
      "Epoch 2866/10000... VAE Loss: 46883.508\n",
      "Epoch 2933/10000... VAE Loss: 46939.0\n",
      "Epoch 3000/10000... VAE Loss: 46921.227\n",
      "Epoch 3066/10000... VAE Loss: 46913.85\n",
      "Epoch 3133/10000... VAE Loss: 46899.32\n",
      "Epoch 3200/10000... VAE Loss: 46909.96\n",
      "Epoch 3266/10000... VAE Loss: 46873.836\n",
      "Epoch 3333/10000... VAE Loss: 46907.06\n",
      "Epoch 3400/10000... VAE Loss: 46889.957\n",
      "Epoch 3466/10000... VAE Loss: 46901.01\n",
      "Epoch 3533/10000... VAE Loss: 46910.406\n",
      "Epoch 3600/10000... VAE Loss: 46887.69\n",
      "Epoch 3666/10000... VAE Loss: 46913.793\n",
      "Epoch 3733/10000... VAE Loss: 46908.047\n",
      "Epoch 3800/10000... VAE Loss: 46900.605\n",
      "Epoch 3866/10000... VAE Loss: 46877.18\n",
      "Epoch 3933/10000... VAE Loss: 46888.023\n",
      "Epoch 4000/10000... VAE Loss: 46875.34\n",
      "Epoch 4066/10000... VAE Loss: 46872.76\n",
      "Epoch 4133/10000... VAE Loss: 46889.43\n",
      "Epoch 4200/10000... VAE Loss: 46886.715\n",
      "Epoch 4266/10000... VAE Loss: 46868.387\n",
      "Epoch 4333/10000... VAE Loss: 46858.88\n",
      "Epoch 4400/10000... VAE Loss: 46864.41\n",
      "Epoch 4466/10000... VAE Loss: 46900.2\n",
      "Epoch 4533/10000... VAE Loss: 46862.64\n",
      "Epoch 4600/10000... VAE Loss: 46885.754\n",
      "Epoch 4666/10000... VAE Loss: 46860.83\n",
      "Epoch 4733/10000... VAE Loss: 46876.086\n",
      "Epoch 4800/10000... VAE Loss: 46907.605\n",
      "Epoch 4866/10000... VAE Loss: 46878.793\n",
      "Epoch 4933/10000... VAE Loss: 46885.363\n",
      "Epoch 5000/10000... VAE Loss: 46900.406\n",
      "Epoch 5066/10000... VAE Loss: 46845.355\n",
      "Epoch 5133/10000... VAE Loss: 46849.676\n",
      "Epoch 5200/10000... VAE Loss: 46900.87\n",
      "Epoch 5266/10000... VAE Loss: 46877.14\n",
      "Epoch 5333/10000... VAE Loss: 46845.645\n",
      "Epoch 5400/10000... VAE Loss: 46877.547\n",
      "Epoch 5466/10000... VAE Loss: 46849.156\n",
      "Epoch 5533/10000... VAE Loss: 46864.16\n",
      "Epoch 5600/10000... VAE Loss: 46886.93\n",
      "Epoch 5666/10000... VAE Loss: 46852.082\n",
      "Epoch 5733/10000... VAE Loss: 46858.293\n",
      "Epoch 5800/10000... VAE Loss: 46916.234\n",
      "Epoch 5866/10000... VAE Loss: 46812.613\n",
      "Epoch 5933/10000... VAE Loss: 46862.66\n",
      "Epoch 6000/10000... VAE Loss: 46866.418\n",
      "Epoch 6066/10000... VAE Loss: 46884.17\n",
      "Epoch 6133/10000... VAE Loss: 46858.19\n",
      "Epoch 6200/10000... VAE Loss: 46891.785\n",
      "Epoch 6266/10000... VAE Loss: 46866.527\n",
      "Epoch 6333/10000... VAE Loss: 46882.414\n",
      "Epoch 6400/10000... VAE Loss: 46887.992\n",
      "Epoch 6466/10000... VAE Loss: 46828.69\n",
      "Epoch 6533/10000... VAE Loss: 46849.297\n",
      "Epoch 6600/10000... VAE Loss: 46897.043\n",
      "Epoch 6666/10000... VAE Loss: 46836.46\n",
      "Epoch 6733/10000... VAE Loss: 46846.25\n",
      "Epoch 6800/10000... VAE Loss: 46901.02\n",
      "Epoch 6866/10000... VAE Loss: 46857.31\n",
      "Epoch 6933/10000... VAE Loss: 46851.066\n",
      "Epoch 7000/10000... VAE Loss: 46904.85\n",
      "Epoch 7066/10000... VAE Loss: 46881.86\n",
      "Epoch 7133/10000... VAE Loss: 46844.8\n",
      "Epoch 7200/10000... VAE Loss: 46876.797\n",
      "Epoch 7266/10000... VAE Loss: 46872.094\n",
      "Epoch 7333/10000... VAE Loss: 46879.54\n",
      "Epoch 7400/10000... VAE Loss: 46903.066\n",
      "Epoch 7466/10000... VAE Loss: 46848.016\n",
      "Epoch 7533/10000... VAE Loss: 46866.43\n",
      "Epoch 7600/10000... VAE Loss: 46895.246\n",
      "Epoch 7666/10000... VAE Loss: 46855.117\n",
      "Epoch 7733/10000... VAE Loss: 46833.863\n",
      "Epoch 7800/10000... VAE Loss: 46860.3\n",
      "Epoch 7866/10000... VAE Loss: 46862.195\n",
      "Epoch 7933/10000... VAE Loss: 46857.504\n",
      "Epoch 8000/10000... VAE Loss: 46841.586\n",
      "Epoch 8066/10000... VAE Loss: 46845.887\n",
      "Epoch 8133/10000... VAE Loss: 46867.69\n",
      "Epoch 8200/10000... VAE Loss: 46850.64\n",
      "Epoch 8266/10000... VAE Loss: 46809.777\n",
      "Epoch 8333/10000... VAE Loss: 46845.383\n",
      "Epoch 8400/10000... VAE Loss: 46875.586\n",
      "Epoch 8466/10000... VAE Loss: 46842.047\n",
      "Epoch 8533/10000... VAE Loss: 46823.24\n",
      "Epoch 8600/10000... VAE Loss: 46872.805\n",
      "Epoch 8666/10000... VAE Loss: 46833.516\n",
      "Epoch 8733/10000... VAE Loss: 46869.453\n",
      "Epoch 8800/10000... VAE Loss: 46869.08\n",
      "Epoch 8866/10000... VAE Loss: 46864.805\n",
      "Epoch 8933/10000... VAE Loss: 46847.1\n",
      "Epoch 9000/10000... VAE Loss: 46864.953\n",
      "Epoch 9066/10000... VAE Loss: 46853.535\n",
      "Epoch 9133/10000... VAE Loss: 46849.504\n",
      "Epoch 9200/10000... VAE Loss: 46895.168\n",
      "Epoch 9266/10000... VAE Loss: 46840.285\n",
      "Epoch 9333/10000... VAE Loss: 46858.723\n",
      "Epoch 9400/10000... VAE Loss: 46860.4\n",
      "Epoch 9466/10000... VAE Loss: 46860.637\n",
      "Epoch 9533/10000... VAE Loss: 46840.527\n",
      "Epoch 9600/10000... VAE Loss: 46855.547\n",
      "Epoch 9666/10000... VAE Loss: 46826.125\n",
      "Epoch 9733/10000... VAE Loss: 46833.023\n",
      "Epoch 9800/10000... VAE Loss: 46855.805\n",
      "Epoch 9866/10000... VAE Loss: 46830.047\n",
      "Epoch 9933/10000... VAE Loss: 46828.87\n",
      "Epoch 10000/10000... VAE Loss: 46854.746\n"
     ]
    }
   ],
   "source": [
    "show_every = 1000\n",
    "show_latent = 250\n",
    "\n",
    "distribut = 'Gaussian'\n",
    "layers = 1\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "dim_img = 28\n",
    "dim_x = dim_img**2\n",
    "dim_z = 6\n",
    "hidden_dim = 500\n",
    "lr = 1e-3\n",
    "epochs = int(1e4)\n",
    "\n",
    "run_name = '%s-%s-layer-full-bs_%s_dimz_%s_dimh_%s_lr_%s' % (distribut, layers, batch_size, dim_z, hidden_dim, lr)\n",
    "projection_data_path = '/Users/aclaudioquiros/Documents/PycCharm/UofG/PhD/MnistVAE/CVAE/'\n",
    "tensorboard_path = '/Users/aclaudioquiros/Documents/PycCharm/UofG/PhD/MnistVAE/CVAE/tensorboard'\n",
    "latent_images = '/Users/aclaudioquiros/Documents/PycCharm/UofG/PhD/MnistVAE/CVAE/latent_images'\n",
    "tb_session = '%s/%s' % (tensorboard_path, run_name)\n",
    "lat_img_run = '%s/%s' % (latent_images, run_name)\n",
    "\n",
    "\n",
    "if os.path.isdir(tb_session):\n",
    "    shutil.rmtree(tb_session)\n",
    "if os.path.isdir(lat_img_run):\n",
    "    shutil.rmtree(lat_img_run)\n",
    "os.makedirs(tb_session)\n",
    "os.makedirs(lat_img_run)\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "vae = CVAE(dim_img=dim_img, dim_x=dim_x, dim_z=dim_z, hidden_dim=hidden_dim, learning_rate=lr)\n",
    "data = Dataset(train_images, train_labels, test_images, test_labels, projection_data_path)\n",
    "\n",
    "iteration = 0\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    summary_writer = tf.summary.FileWriter(tb_session, graph_def=sess.graph_def)\n",
    "    sess.run(vae.init)    \n",
    "    for e in range(epochs+1):\n",
    "        for images, labels in data.batches(batch_size):\n",
    "            \n",
    "            labels = np.reshape(labels, (-1, 1))\n",
    "                \n",
    "            # Train and store data \n",
    "            sess.run(vae.vae_opt, feed_dict={vae.x_input: images, vae.y_input: labels})\n",
    "            summary_str, vae_loss, vae_mean_z_g_xi = sess.run([vae.merged_summary_op, vae.vae_loss, vae.mean_z_g_xi], feed_dict={vae.x_input: images, vae.y_input: labels})\n",
    "            summary_writer.add_summary(summary_str, iteration)\n",
    "            \n",
    "            if iteration%show_every==0:\n",
    "                # Run batch and print loss.\n",
    "                print('Epoch %s/%s... VAE Loss: %s' % (str(e), str(epochs), str(vae_loss)))\n",
    "            iteration += 1\n",
    "            \n",
    "        if e%show_latent == 0:\n",
    "            plot_samples(vae, sess, lat_img_run, e)\n",
    "\n",
    "#     data.create_sprite_image(data.test_img)\n",
    "#     data.create_tsv_file(data.test_labels)\n",
    "#     mean_z_g_xi = sess.run(vae.mean_z_g_xi, feed_dict={vae.x_input: data.test_img})\n",
    "#     latent = tf.Variable(mean_z_g_xi, name='Latent_Space_Z_%s' % e)\n",
    "    \n",
    "#     saver = tf.train.Saver([latent])\n",
    "#     sess.run(latent.initializer)\n",
    "#     saver.save(sess, os.path.join(tb_session, 'latent_%s.ckpt' % e))\n",
    "#     config = projector.ProjectorConfig()\n",
    "#     embedding = config.embeddings.add()\n",
    "#     embedding.tensor_name = latent.name\n",
    "#     embedding.sprite.image_path = data.sprite\n",
    "#     embedding.sprite.single_image_dim.extend([28,28])\n",
    "#     embedding.metadata_path = data.metadata_tsv\n",
    "    \n",
    "#     projector.visualize_embeddings(summary_writer, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1.0,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1.0,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16.0,
    "lenType": 16.0,
    "lenVar": 40.0
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "689.219px",
    "left": "844.848px",
    "right": "20px",
    "top": "115.945px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
